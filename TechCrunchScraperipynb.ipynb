{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":19797,"status":"ok","timestamp":1725483695702,"user":{"displayName":"Mitchel Crosson","userId":"11140833460202076022"},"user_tz":300},"id":"GOo1Er4zJ9oB","outputId":"2ffd8268-0c48-4537-c7a5-e6a9984fea32"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.24.0)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n","Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.26.2)\n","Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.8)\n","Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n","Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n","Requirement already satisfied: google-colab-selenium in /usr/local/lib/python3.10/dist-packages (1.0.14)\n","Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (from google-colab-selenium) (4.24.0)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google-colab-selenium) (2.0.7)\n","Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (0.26.2)\n","Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (0.11.1)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (2024.8.30)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (4.12.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (1.8.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (24.2.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (3.8)\n","Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (1.3.0.post0)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (1.2.2)\n","Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium->google-colab-selenium) (1.2.0)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google-colab-selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google-colab-selenium) (0.14.0)\n"]}],"source":["!pip install selenium\n","!pip install google-colab-selenium"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8OabJTwFIUA"},"outputs":[],"source":["import google_colab_selenium as gs\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMeOcDeWNBWi"},"outputs":[],"source":["def scrape_techcrunch_links():\n","    term = \"ai\"\n","    url = f\"https://techcrunch.com/?s={term}\"\n","    driver = gs.Chrome()\n","    driver.get(url)\n","\n","    linksraw = driver.find_elements(\"xpath\", \"//h2//a[@href]\")\n","\n","    links = set()\n","    for link in linksraw:\n","        link = link.get_attribute(\"href\")\n","        links.add(link)\n","\n","    driver.quit()\n","    return links\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tvIyVX54T_Ih"},"outputs":[],"source":["def scrape_techcrunch_articles(links):\n","  pairs = {}\n","  m = 0\n","  for i in list(links):\n","    url = i\n","    driver = gs.Chrome()\n","    driver.get(url)\n","\n","    titles = driver.find_elements(\"xpath\", \"//h1[@class='wp-block-post-title']\")\n","    text = driver.find_elements(\"xpath\", \"//p\")\n","\n","    for k in titles:\n","      title = str(k.text)\n","\n","    textcorpus = []\n","    for j in text:\n","      textcorpus.append(j.text)\n","\n","    texter = \"\"\n","    for i in textcorpus:\n","      texter = texter + \" \" + i\n","\n","    pairs[title] = texter\n","\n","    print(m)\n","    m = m + 1\n","    # if m == 2:\n","    #   break\n","\n","  driver.quit()\n","  return pairs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"elapsed":44459,"status":"ok","timestamp":1725483740660,"user":{"displayName":"Mitchel Crosson","userId":"11140833460202076022"},"user_tz":300},"id":"J6L10YdGOmaV","outputId":"5f575b0c-196c-4f3f-8c53-91591b8a100b"},"outputs":[{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"ec5af17f-df91-4f0d-9b04-f67a394ce726-circle\"></div>\n","                <div class=\"spinner-text\" id=\"ec5af17f-df91-4f0d-9b04-f67a394ce726-text\">Updating and upgrading APT</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"ec5af17f-df91-4f0d-9b04-f67a394ce726-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"ec5af17f-df91-4f0d-9b04-f67a394ce726-text\");\n            text.innerText = \"Updated and upgraded APT\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"f938f072-b559-4fe5-890f-ea765a9bacd1-circle\"></div>\n","                <div class=\"spinner-text\" id=\"f938f072-b559-4fe5-890f-ea765a9bacd1-text\">Downloading Google Chrome</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"f938f072-b559-4fe5-890f-ea765a9bacd1-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"f938f072-b559-4fe5-890f-ea765a9bacd1-text\");\n            text.innerText = \"Downloaded Google Chrome\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"452872c8-4ec1-4e43-ab65-0272e2b46abf-circle\"></div>\n","                <div class=\"spinner-text\" id=\"452872c8-4ec1-4e43-ab65-0272e2b46abf-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"452872c8-4ec1-4e43-ab65-0272e2b46abf-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"452872c8-4ec1-4e43-ab65-0272e2b46abf-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["techcrunch_links = scrape_techcrunch_links()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3134488,"status":"ok","timestamp":1725486875142,"user":{"displayName":"Mitchel Crosson","userId":"11140833460202076022"},"user_tz":300},"id":"2jxMj0UdYRb4","outputId":"c55ea7a3-ba63-4343-c5d9-c8221c3c3544"},"outputs":[{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"895e6491-a5e0-47c6-99f1-83106d3536af-circle\"></div>\n","                <div class=\"spinner-text\" id=\"895e6491-a5e0-47c6-99f1-83106d3536af-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"895e6491-a5e0-47c6-99f1-83106d3536af-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"895e6491-a5e0-47c6-99f1-83106d3536af-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["0\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"2a6da1a1-0899-4cd5-90f3-1dcf6f6077fb-circle\"></div>\n","                <div class=\"spinner-text\" id=\"2a6da1a1-0899-4cd5-90f3-1dcf6f6077fb-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"2a6da1a1-0899-4cd5-90f3-1dcf6f6077fb-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"2a6da1a1-0899-4cd5-90f3-1dcf6f6077fb-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["1\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"3884f821-0d89-445d-8c90-c04c827c1c61-circle\"></div>\n","                <div class=\"spinner-text\" id=\"3884f821-0d89-445d-8c90-c04c827c1c61-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"3884f821-0d89-445d-8c90-c04c827c1c61-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"3884f821-0d89-445d-8c90-c04c827c1c61-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["2\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"aa91dd95-01c7-4856-88ec-2168cdd5aa1a-circle\"></div>\n","                <div class=\"spinner-text\" id=\"aa91dd95-01c7-4856-88ec-2168cdd5aa1a-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"aa91dd95-01c7-4856-88ec-2168cdd5aa1a-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"aa91dd95-01c7-4856-88ec-2168cdd5aa1a-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["3\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"36137aac-90bb-4c22-8914-dc2426d14abb-circle\"></div>\n","                <div class=\"spinner-text\" id=\"36137aac-90bb-4c22-8914-dc2426d14abb-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"36137aac-90bb-4c22-8914-dc2426d14abb-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"36137aac-90bb-4c22-8914-dc2426d14abb-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["4\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"abbff34b-669d-4c95-b659-726dd9fe4f65-circle\"></div>\n","                <div class=\"spinner-text\" id=\"abbff34b-669d-4c95-b659-726dd9fe4f65-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"abbff34b-669d-4c95-b659-726dd9fe4f65-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"abbff34b-669d-4c95-b659-726dd9fe4f65-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["5\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"663a199c-78d3-4254-9125-5e28bffba1a1-circle\"></div>\n","                <div class=\"spinner-text\" id=\"663a199c-78d3-4254-9125-5e28bffba1a1-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"663a199c-78d3-4254-9125-5e28bffba1a1-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"663a199c-78d3-4254-9125-5e28bffba1a1-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["6\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"6724347d-a6bd-4941-b07c-086d28291081-circle\"></div>\n","                <div class=\"spinner-text\" id=\"6724347d-a6bd-4941-b07c-086d28291081-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"6724347d-a6bd-4941-b07c-086d28291081-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"6724347d-a6bd-4941-b07c-086d28291081-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["7\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"94a5acff-4689-49f8-a33d-14865a6989a6-circle\"></div>\n","                <div class=\"spinner-text\" id=\"94a5acff-4689-49f8-a33d-14865a6989a6-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"94a5acff-4689-49f8-a33d-14865a6989a6-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"94a5acff-4689-49f8-a33d-14865a6989a6-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["8\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"3c48b6a8-0976-4dd2-a72c-ef5d591feeeb-circle\"></div>\n","                <div class=\"spinner-text\" id=\"3c48b6a8-0976-4dd2-a72c-ef5d591feeeb-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"3c48b6a8-0976-4dd2-a72c-ef5d591feeeb-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"3c48b6a8-0976-4dd2-a72c-ef5d591feeeb-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["9\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"ce745dfb-b462-4399-8f76-972aa387cbf2-circle\"></div>\n","                <div class=\"spinner-text\" id=\"ce745dfb-b462-4399-8f76-972aa387cbf2-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"ce745dfb-b462-4399-8f76-972aa387cbf2-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"ce745dfb-b462-4399-8f76-972aa387cbf2-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["10\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"c06f56ae-a5aa-45ab-8df2-e82aa5b9b325-circle\"></div>\n","                <div class=\"spinner-text\" id=\"c06f56ae-a5aa-45ab-8df2-e82aa5b9b325-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"c06f56ae-a5aa-45ab-8df2-e82aa5b9b325-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"c06f56ae-a5aa-45ab-8df2-e82aa5b9b325-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["11\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"2ed2039c-3031-4067-958d-71ff103c1325-circle\"></div>\n","                <div class=\"spinner-text\" id=\"2ed2039c-3031-4067-958d-71ff103c1325-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"2ed2039c-3031-4067-958d-71ff103c1325-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"2ed2039c-3031-4067-958d-71ff103c1325-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["12\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"7f9d273e-0a4a-461b-9733-95cd3680dedd-circle\"></div>\n","                <div class=\"spinner-text\" id=\"7f9d273e-0a4a-461b-9733-95cd3680dedd-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"7f9d273e-0a4a-461b-9733-95cd3680dedd-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"7f9d273e-0a4a-461b-9733-95cd3680dedd-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["13\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"e8d9c8e4-ac90-49e3-bf43-9465fd31315f-circle\"></div>\n","                <div class=\"spinner-text\" id=\"e8d9c8e4-ac90-49e3-bf43-9465fd31315f-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"e8d9c8e4-ac90-49e3-bf43-9465fd31315f-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"e8d9c8e4-ac90-49e3-bf43-9465fd31315f-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["14\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"8abf6004-4a6d-4830-ba57-89d0c0777cc6-circle\"></div>\n","                <div class=\"spinner-text\" id=\"8abf6004-4a6d-4830-ba57-89d0c0777cc6-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"8abf6004-4a6d-4830-ba57-89d0c0777cc6-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"8abf6004-4a6d-4830-ba57-89d0c0777cc6-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["15\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"1050bee2-2625-424b-8b51-57070c154aac-circle\"></div>\n","                <div class=\"spinner-text\" id=\"1050bee2-2625-424b-8b51-57070c154aac-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"1050bee2-2625-424b-8b51-57070c154aac-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"1050bee2-2625-424b-8b51-57070c154aac-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["16\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"367b2cc1-51d0-4d80-b706-a37599164c2b-circle\"></div>\n","                <div class=\"spinner-text\" id=\"367b2cc1-51d0-4d80-b706-a37599164c2b-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"367b2cc1-51d0-4d80-b706-a37599164c2b-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"367b2cc1-51d0-4d80-b706-a37599164c2b-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["17\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"ef6a9106-e393-4a27-9998-c03c686d3a6f-circle\"></div>\n","                <div class=\"spinner-text\" id=\"ef6a9106-e393-4a27-9998-c03c686d3a6f-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"ef6a9106-e393-4a27-9998-c03c686d3a6f-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"ef6a9106-e393-4a27-9998-c03c686d3a6f-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["18\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"01045d04-3f7f-4da5-b642-84be1187cfcd-circle\"></div>\n","                <div class=\"spinner-text\" id=\"01045d04-3f7f-4da5-b642-84be1187cfcd-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"01045d04-3f7f-4da5-b642-84be1187cfcd-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"01045d04-3f7f-4da5-b642-84be1187cfcd-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["19\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"47c6223a-dbc1-4700-b58c-82472a02ec9b-circle\"></div>\n","                <div class=\"spinner-text\" id=\"47c6223a-dbc1-4700-b58c-82472a02ec9b-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"47c6223a-dbc1-4700-b58c-82472a02ec9b-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"47c6223a-dbc1-4700-b58c-82472a02ec9b-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["20\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"55f78fa4-555b-4b12-b6dd-c3754c2fb100-circle\"></div>\n","                <div class=\"spinner-text\" id=\"55f78fa4-555b-4b12-b6dd-c3754c2fb100-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"55f78fa4-555b-4b12-b6dd-c3754c2fb100-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"55f78fa4-555b-4b12-b6dd-c3754c2fb100-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["21\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"110c8672-7177-43c6-a423-0d465a28c45a-circle\"></div>\n","                <div class=\"spinner-text\" id=\"110c8672-7177-43c6-a423-0d465a28c45a-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"110c8672-7177-43c6-a423-0d465a28c45a-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"110c8672-7177-43c6-a423-0d465a28c45a-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["22\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"a0384d3b-f483-4be1-9628-7515e5e77f97-circle\"></div>\n","                <div class=\"spinner-text\" id=\"a0384d3b-f483-4be1-9628-7515e5e77f97-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"a0384d3b-f483-4be1-9628-7515e5e77f97-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"a0384d3b-f483-4be1-9628-7515e5e77f97-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["23\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"b089e8bd-5c9e-42e4-8f5f-6af898820288-circle\"></div>\n","                <div class=\"spinner-text\" id=\"b089e8bd-5c9e-42e4-8f5f-6af898820288-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"b089e8bd-5c9e-42e4-8f5f-6af898820288-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"b089e8bd-5c9e-42e4-8f5f-6af898820288-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["24\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"ed289259-b858-449a-b3f7-169d8ee1c97f-circle\"></div>\n","                <div class=\"spinner-text\" id=\"ed289259-b858-449a-b3f7-169d8ee1c97f-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"ed289259-b858-449a-b3f7-169d8ee1c97f-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"ed289259-b858-449a-b3f7-169d8ee1c97f-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["25\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"233bec41-5562-4b40-ad2d-af3ad4c1c423-circle\"></div>\n","                <div class=\"spinner-text\" id=\"233bec41-5562-4b40-ad2d-af3ad4c1c423-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"233bec41-5562-4b40-ad2d-af3ad4c1c423-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"233bec41-5562-4b40-ad2d-af3ad4c1c423-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["26\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"f0649ffe-8c43-413d-b492-da6659ecf974-circle\"></div>\n","                <div class=\"spinner-text\" id=\"f0649ffe-8c43-413d-b492-da6659ecf974-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"f0649ffe-8c43-413d-b492-da6659ecf974-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"f0649ffe-8c43-413d-b492-da6659ecf974-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["27\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"bb338f27-a973-41d1-b760-579ba2d5c7cd-circle\"></div>\n","                <div class=\"spinner-text\" id=\"bb338f27-a973-41d1-b760-579ba2d5c7cd-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"bb338f27-a973-41d1-b760-579ba2d5c7cd-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"bb338f27-a973-41d1-b760-579ba2d5c7cd-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["28\n"]},{"data":{"text/html":["\n","            <div class=\"spinner-container\">\n","                <div class=\"spinner\" id=\"da905a2b-5fd6-498d-8e70-4c3971777b62-circle\"></div>\n","                <div class=\"spinner-text\" id=\"da905a2b-5fd6-498d-8e70-4c3971777b62-text\">Initializing Chromedriver</div>\n","            </div>\n","            <style>\n","                @keyframes spin {\n","                    from { transform: rotate(0deg); }\n","                    to { transform: rotate(360deg); }\n","                }\n","\n","                .spinner-container {\n","                    display: flex;\n","                    align-items: center;\n","                    margin-bottom: 3px;\n","                }\n","\n","                .spinner {\n","                    border: 3px solid rgba(0, 0, 0, 0.1);\n","                    border-left-color: lightblue;\n","                    border-radius: 50%;\n","                    width: 12px;\n","                    height: 12px;\n","                    animation: spin 1s linear infinite;\n","                }\n","\n","                .spinner-text {\n","                    padding-left: 6px;\n","                }\n","            </style>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"\n            const element = document.getElementById(\"da905a2b-5fd6-498d-8e70-4c3971777b62-circle\");\n            element.style.border = \"3px solid limegreen\";\n            element.style.animation = \"none\";\n\n            const text = document.getElementById(\"da905a2b-5fd6-498d-8e70-4c3971777b62-text\");\n            text.innerText = \"Initialized Chromedriver\";\n        ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["29\n","{'OmniAI transforms business data for AI': ' Comment The majority of companies struggle to extract value from their data. Several years ago, Forrester reported that between 60% and 73% of data belonging to the average business goes unused for analytics. That’s because the data’s siloed or otherwise pigeonholed by technical and security considerations, making it difficult — if not impossible — to apply analytical tools. Anna Pojawis and Tyler Maran, engineers who previously did stints at Y Combinator-backed startups Hightouch (a data-syncing platform) and Fair Square (a health insurance tool), were inspired to try their hands at solving the data value problem after discovering that many companies had been “locked out” of analytics strategies due to the engineering roadblocks. “We’ve found that a significant part of the market, especially those in regulated industries like healthcare and finance,” have struggled with data analytics, Maran told TechCrunch. “The majority of corporate data doesn’t fit into a database today; it’s sales calls, documents, Slack messages and so on. And, given the scale of these companies, off-the-shelf data models are typically not sufficient.” So Pojawis and Maran founded OmniAI, a set of tools that transform unstructured enterprise data into something that data analytics apps and AI can understand. OmniAI syncs with a company’s data storage services and databases (e.g., Snowflake, MongoDB, etc.), preps the data within and allows companies to run the model of their choice — for example, a large language model — on the data. OmniAI performs all of its work in the company’s cloud, OmniAI’s private cloud or on-premises environments, delivering ostensibly improved security, according to Maran. “We believe that large language models will become essential to a company’s infrastructure in the next decade, and having everything hosted in one place just makes sense,” Maran said. Out of the box, OmniAI offers integrations with models, including Meta’s Llama 3, Anthropic’s Claude, Mistral’s Mistral Large and Amazon’s AWS Titan for use cases like automatically redacting sensitive information from data and generally building AI-powered applications. Customers sign a software-as-a-service contract with OmniAI to enable management of models on their infrastructure. It’s early days. But Omni, which recently closed a $3.2 million seed round led by FundersClub at a $30 million valuation, claims to have 10 customers already, including Klaviyo and Carrefour. Annual recurring revenue is on track to reach $1 million by 2025, Maran said. “We’re an incredibly lean team in a fast-growing industry,” Maran said. “Our bet is that, over time, companies will opt for running models alongside their existing infrastructure, and model providers will focus more on licensing model weights to existing cloud providers.” Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Mayfield allocates $100M to AI incubator modeled after its entrepreneur-in-residence program': ' Comment Navin Chaddha, the leader and managing partner of 55-year-old VC firm Mayfield Fund, has a penchant for approaching venture investing in a way that deviates slightly from other established firms. When Mayfield raised a $955 million fund last year, Chaddha told TechCrunch the firm didn’t need a multibillion-dollar fund because “copying somebody else is strategy for disaster, strategy for failure.” The firm is again trying to do something that it sees as unique. On Wednesday, Mayfield said it is launching AI Garage, a $100 million initiative for ideation-stage founders interested in building “AI teammate” companies. AI Garage wants to distinguish itself from accelerators such as YC or pre-seed programs like Sequoia’s Arc or Greylock’s Edge by modeling the effort on its entrepreneur-in-residence (EIR) experience. For the past 40 years, Mayfield Fund has hired one or two EIRs each year and helped them turn a raw concept into a new, fundable company. With the new program, Mayfield plans to scale and formalize its EIR program by welcoming up to five aspiring founders into its office every six months.   Just like with EIRs, AI Garage participants won’t receive capital on day one, but Mayfield will allocate a minimum of $1 million and as much as $5 million as soon as the business plan is hatched with the help of a firm’s partners and other support staff, including marketing, talent and business development team. As for why Mayfield decided to quintuple and formalize its EIR program, the answer comes down to Chaddha’s interest in getting early access to AI application startups, specifically in the area he calls “AI teammates.” “They haven’t even started the company. We will help them start it,” Chaddha said. According to Chaddha, AI teammates differ from copilots and agents because they are more than simple assistants, which can answer questions or perform actions autonomously, like booking meetings or offering refunds. “Teammates collaborate with humans on complex tasks to achieve a shared goal,” he said. “AI teammates are digital companions that elevate humans to superhumans. They are going to take us into a new era of collaborative intelligence.” Although the terms “copilot,” “agent” and “teammate” can be used interchangeably, labeling an AI app as a teammate can be seen as a clever marketing tactic because it just seems more human-friendly. “We believe there are endless opportunities for AI teammates to collaborate with humans and to shape the future of our workplace by having AI work together with humans in many areas, including product and engineering, data, sales and marketing, customer service, IT and security, finance, HR, legal and many administrative functions,” Chaddha said. Mayfield has already invested in nearly a dozen AI teammate companies, including DevRev (customer service support AI), Docket (an AI sales engineer) and NeuBird (site reliability AI engineer.) In NeuBird’s case, human site reliability engineers tell its AI to detect any site outages, and then triage and troubleshoot problems. If the AI discovers it can’t fix the problem, it calls human engineers for help. “That’s an example of a teammate,” Chaddha said.  Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                       Featured Article         Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'At the AI Film Festival, humanity triumphed over tech': ' Comment In the third episode of “Creative Dialogues,” an interview series produced by the filmmaking division of generative AI startup Runway, multimedia artist Claire Hentschker expresses a fear that AI will commoditize the artistic process to the point where art homogenizes, regressing to a sort of derivative sameness. “Are you getting this increasingly narrower average of existing things?” she asks. “And then — as that keeps getting averaged — is everything is just gonna be a blob?” Those are the questions I kept asking myself Wednesday at a showing of the top 10 finalists at Runway’s second annual AI Film Festival, which are available on-demand on Runway’s website as of this morning. Runway held two premieres this year, one in Los Angeles and a second in New York. I attended New York’s, which took place at Metrograph, a theater known for its arthouse and avant-garde bookings. I’m pleased to report that AI isn’t hastening in a blob future … not yet at least. But a skilled directorial eye — the human touch — makes a clear difference in an “AI film’s” effectiveness. All of the movies submitted to the festival incorporated AI in some form, including AI-generated backdrops and animations, synthetic voice-overs, and bullet time-style special effects. None of the elements seemed quite to the level of what state-of-the-art tools like OpenAI’s Sora can produce, but that was to be expected, given that most of the submissions were finalized early in the year. Indeed, it tended to be obvious — sometimes painfully so — which parts of films were the product of an AI model, not an actor, cameraman or animator. Even otherwise strong scripts were sometimes let down by underwhelming generative AI effects. Take, for example, “Dear Mom” by Johans Saldana Guadalupe and Katie Luo, which recounts the story of a daughter’s loving relationship with her mother — in the daughter’s own words. It’s a tearjerker. But a scene of a Los Angeles freeway with all the telltale weirdness of AI-generated video (e.g., warped cars, bizarre physics) broke the spell for me. The limitations of today’s AI tools seemed to box some films in. As my colleague Devin Coldewey recently wrote, control with generative models — particularly video-generating ones — is elusive. Simple matters in traditional filmmaking, like choosing a color in a character’s clothing, require workarounds because each shot is created independently of the others. Sometimes not even workarounds do the trick. The resulting disjointedness was on display at the festival, where several of the films were little more than tangentially related vignettes strung together by narration and a soundtrack. “L’éveil à la création” by Carlo De Togni and Elena Sparacino demonstrated just how dull this formula can be, with slideshow-like transitions that would make for a better interactive storybook than film. Léo Cannone’s “Where Do Grandmas Go When They Get Lost?” falls into the vignettes category as well — but triumphs despite this thanks to a heartfelt script (a child describing what happens to grandmothers after they pass) and an exceptionally strong performance from its child star. The rest of the audience seemed to agree; the film got one of the more spirited rounds of applause of the night. And for me, that really sums up the festival in a nutshell. The human — not AI — contributions often make all the difference. The emotionality in a child actor’s voice? That sticks with you. AI-generated backdrops? Less so. This was certainly true for festival Grand Prix winner “Get Me Out,” which documents one Japanese man’s struggle to recover from the psychological toll of his immigration to the U.S. as a young child. Filmmaker Daniel Antebi depicts the man’s panic attacks with the help of AI-generated graphics — graphics that I found to be less successful, ultimately, than the cinematography. The film ends with a shot of the man walking up a bridge just as the streetlights dotting the pedestrian lane flicker on one by one. It’s haunting — and beautiful — and surely took ages to capture just so. It’s very possible that generative AI will one day be able to re-create scenes like this. Perhaps cinematography will eventually be replaced with prompts — a victim of the ever-growing datasets (albeit with troubling copyright status) on which startups such as Runway and OpenAI are training their video-generating models. But that day isn’t today. As the screening wrapped up and the award recipients marched to the front of the theater for a photo op, I couldn’t help but notice the cameraman in the corner documenting the whole affair. Maybe, on the contrary, AI will never replace some things, like the humanity we humans deeply crave. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Microsoft dodges UK antitrust scrutiny over its Mistral AI stake': ' Featured Article Comment Microsoft won’t be facing antitrust scrutiny in the U.K. over its recent investment in French AI startup, Mistral AI, with the country’s Competition and Markets Authority (CMA) on Friday concluding that the partnership “does not qualify for investigation under the merger provisions of the Enterprise Act 2002.” The decision comes three weeks after the CMA revealed a trio of early-stage probes into Amazon and Microsoft’s various AI investments and partnerships, including the Redmond-based company’s $16 million investment in Mistral AI, an OpenAI rival working on large language models. Shortly after, Microsoft hired the team behind Inflection AI, another OpenAI rival, essentially gutting the startup. Elsewhere, the CMA said it was also poking at Amazon’s $4 billion investment in Anthropic, a U.S.-based AI company working on large language models. There has been growing scrutiny of Big Tech’s latest tactic to dodge regulatory oversight by pursuing “quasi-mergers,” through which they seek to secure control over new technologies without buying startups outright. This might be through making investments, procuring seats on boards, hiring founding teams and so on. Early in 2024, the Federal Trade Commission (FTC) launched investigations into Alphabet, Amazon and Microsoft’s investments in emerging AI firms to establish whether the “partnerships pursued by dominant companies risk distorting innovation and undermining fair competition.” The CMA’s efforts are part of that same regulatory push. Two of its recently announced “invitations to comment” are still ongoing, and may lead to formal in-depth probes. Still, it’s telling that the CMA is throwing out the Mistral AI case on the grounds that it doesn’t “qualify” for investigation under existing rules. Alex Haffner, competition partner at U.K. law firm Fladgate, says this finding suggests that the structure of Microsoft’s partnership with Mistral AI doesn’t grant the bigger company sufficient rights or influence, at least as it relates to M&A regulation. Ultimately, it was a minority investment into a double-unicorn that had closed a $415 million round just a few months earlier. “In so doing, the decision vindicates Microsoft’s stated position on the tie-up,” Haffner said. This “stated position” was that making a small investment isn’t enough to procure meaningful clout in the future direction of an up-and-coming AI startup. Microsoft would effectively own less than 1% of Mistral AI when its investment converts to equity at the French startup’s next funding round. A Microsoft spokesperson said at the time of the CMA’s initial probe announcement: “We remain confident that common business practices such as the hiring of talent or making a fractional investment in an AI startup promote competition and are not the same as a merger.” While the CMA maintains that Big Tech could be adopting new methods to protect themselves from antitrust scrutiny, it has now confirmed that Microsoft hadn’t acquired any “material influence on Mistral AI’s commercial policy.” “The CMA has considered information submitted by Microsoft and Mistral AI, together with feedback received in response to its invitation to comment,” a CMA spokesperson said. “Based on the evidence, the CMA does not believe that Microsoft has acquired material influence over Mistral AI as a result of the partnership and therefore does not qualify for investigation.” Just last month, the CMA sounded an alarm over Big Tech’s waxing influence on the advanced AI market, expressing concerns over the growing connection and concentration between developers in the snowballing generative AI space. But the CMA has now said that at least one of the deals on its radar doesn’t qualify for investigation, suggesting that Big Tech’s tactics to pollinate the AI ecosystem far and wide might be working to a degree. But that still leaves two more outstanding cases: Amazon’s gargantuan investment in Anthropic, and Microsoft’s hiring of key Inflection personnel. Could we expect a similar outcome there? “The CMA has concluded that the arrangements between Microsoft and Mistral are not sufficient to give Microsoft ‘material influence’ over Mistral, which is the relevant jurisdictional test,” Haffner said. “Time will tell, but the assumption is therefore that the application of the test is more clear-cut here than with the other AI partnerships under investigation by the CMA.” It’s certainly not as cut-and-dry. Anthropic got Amazon’s biggest venture investment to date, constituting more than half of the $7.6 billion the AI company has raised since its inception three years ago. And while Inflection technically still exists, Microsoft scooped up its founders and various key colleagues — in many ways, that was as good as an acquisition. And let’s not forget about the CMA’s other separate, but related, ongoing case looking at Microsoft’s close ties with OpenAI. The regulator launched a formal “invitation to comment” aimed at relevant stakeholders in the AI and business spheres last year, and the European Commission (EC) followed suit in January. So we probably shouldn’t make too many conclusions about the other pending cases based on today’s news. “That the CMA has only confirmed the conclusions of the Mistral investigation is interesting, as it leaves open the position on the other two deals, as well as the CMA’s ongoing investigation into Microsoft’s role in the OpenAI project,” Haffner said. “Overall, therefore, it is clear that the competition authorities are continuing to engage very closely with developments in the AI sector, and we can expect several more announcements by the CMA in the near future as to the outcome of their ongoing workstreams in this space.”  We’re launching an AI newsletter! Sign up here to start receiving it in your inboxes on June 5. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'EU calls for help with shaping rules for general-purpose AIs': ' Comment The European Union has kicked off a consultation on rules that will apply to providers of general-purpose AI models (GPAIs) — such as Anthropic, Google, Microsoft and OpenAI — under the bloc’s AI Act, its risk-based framework for regulating applications of artificial intelligence. Lawmakers want the Code of Practice to help ensure “trustworthy” GPAIs by providing developers with guidance on how to comply with their legal obligations. The EU AI Act was adopted earlier this year and will come into force imminently, on August 1. But it has a phased implementation for compliance deadlines, and Codes of Practice are due to apply after nine months — so April 2025. That gives the bloc time to draw up the guidance. The Commission is inviting responses to the consultation from GPAI providers who have operations in the EU, as well as from businesses, civil society representatives, rights holders, and academic experts. “The consultation is an opportunity for all stakeholders to have their say on the topics covered by the first Code of Practice, which will detail out rules for general-purpose AI model providers,” the Commission wrote. “The consultation will also inform related work by the AI Office, in particular on the template for the summary of the content used for the training of the general-purpose AI models and the accompanying guidance.” The consultation is a questionnaire divided into three sections. One covers transparency and copyright-related provisions for GPAIs; the second is concerned with rules on risk taxonomy, assessment and mitigation for GPAIs with so called systemic risk (defined in the AI Act as models trained above a certain compute threshold); and the third section deals with the reviewing and monitoring of Codes of Practices for GPAIs. The Commission said an initial draft Code will be developed “based on the submissions and answers to the targeted questions.” Those responding to the consultation have the chance to influence the shape of the template the AI Office will provide to GPAI providers so they can fulfill a legal requirement to provide a summary of model training content. It will be interesting to watch how detailed that template ends up being. More information on the consultation can be found here. The deadline for submissions is September 10, 2024, at 6 p.m. CET. The EU is also calling for an expression of interest to participate in drawing up the Code via virtual meetings divided into four working groups. An iterative drafting process will be used to develop the guidance. The AI Office is inviting “eligible general-purpose AI model providers, downstream providers and other industry organisations, other stakeholder organisations such as civil society organisations or rightsholders organisations, as well as academia and other independent experts to express their interest to participate in the drawing-up of the Code of Practice.”  The deadline for submitting an expression of interest to participate in the drafting is August 25, 2024, at 6 p.m. CET. In addition, GPAI providers will get the chance to attend workshops with the plenary meeting chairs and vice chairs. These workshops, the AI Office said, are intended to “contribute to informing each iterative drafting round, in addition to their Plenary participation.” “The AI Office will ensure transparency into these discussions, such as by drawing-up meeting minutes and making these available to all Plenary participants,” it noted. The AI Office itself will appoint meeting chairs and vice chairs. It is taking applications from “interested independent experts” for these key steering roles. The call and the consultation on the Code follow concerns that civil society organizations might be excluded from the drafting process. Earlier this month, Euractiv reported that the Commission was intending to rely on consultancy firms to draft the Code, leading to concerns of a skewed process that could favor AI giants. The Commission sounds keen to dispel any such concerns. “All interested parties are encouraged to participate,” it wrote on Tuesday. “The AI Office invites submissions from a broad range of stakeholders, including academia, independent experts, industry representatives such as general-purpose AI model providers or downstream providers integrating the model into their AI systems, civil society organisations, rightsholders, and public authorities.” Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                 Featured Article           Featured Article     Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Study suggests that even the best AI models hallucinate a bunch': ' Comment All generative AI models hallucinate, from Google’s Gemini to Anthropic’s Claude to the latest stealth release of OpenAI’s GPT-4o. The models are unreliable narrators in other words — sometimes to hilarious effect, other times problematically so. But not all models make things up at the same rate. And the kinds of mistruths they spout depend on which sources of info they’ve been exposed to. A recent study from researchers at Cornell, the universities of Washington and Waterloo and the nonprofit research institute AI2 sought to benchmark hallucinations by fact-checking models like GPT-4o against authoritative sources on topics ranging from law and health to history and geography. They found that no model performed exceptionally well across all topics, and that models that hallucinated the least did so partly because they refused to answer questions they’d otherwise get wrong. “The most important takeaway from our work is that we cannot yet fully trust the outputs of model generations,” Wenting Zhao, a doctorate student at Cornell and a co-author on the research, told TechCrunch. “At present, even the best models can generate hallucination-free text only about 35% of the time.” There’s been other academic attempts at probing the “factuality” of models, including one by a separate AI2-affiliated team. But Zhao notes that these earlier tests asked models questions with answers easily found on Wikipedia — not exactly the toughest ask, considering most models are trained on Wikipedia data. To make their benchmark more challenging — and to more accurately reflect the types of questions people ask of models — the researchers identified topics around the web that don’t have a Wikipedia reference. Just over half the questions in their test can’t be answered using Wikipedia (they included some Wikipedia-sourced ones for good measure), and touch on topics including culture, geography, astronomy, pop culture, finance, medicine, computer science and celebrities. For their study, the researchers evaluated over a dozen different popular models, many of which were released in the past year. In addition to GPT-4o, they tested “open” models such as Meta’s Llama 3 70B, Mistral’s Mixtral 8x22B and Cohere’s Command R+, as well as gated-behind-API models like Perplexity’s Sonar Large (which is based on Llama), Google’s Gemini 1.5 Pro and Anthropic’s Claude 3 Opus. The results suggest that models aren’t hallucinating much less these days, despite claims to the contrary from OpenAI, Anthropic and the other big generative AI players. GPT-4o and OpenAI’s much older flagship GPT-3.5 performed about the same in terms of the percentage of questions they answered factually correctly on the benchmark. (GPT-4o was marginally better.) OpenAI’s models were the least hallucinatory overall, followed by Mixtral 8x22B, Command R and Perplexity’s Sonar models. Questions pertaining to celebrities and finance gave the models the hardest time, but questions about geography and computer science were easiest for the models to answer (perhaps because their training data contained more references to these). In cases where the source of an answer wasn’t Wikipedia, every model answered less factually on average (but especially GPT-3.5 and GPT-4o), suggesting that they’re all informed heavily by Wikipedia content. Even models that can search the web for information, like Command R and Perplexity’s Sonar models, struggled with “non-Wiki” questions in the benchmark. Model size didn’t matter much; smaller models (e.g. Anthropic’s Claude 3 Haiku) hallucinated roughly as frequently as larger, ostensibly more capable models (e.g. Claude 3 Opus). So what does all this mean — and where are the improvements that vendors promised? Well, we wouldn’t put it past vendors to exaggerate their claims. But a more charitable take is the benchmarks they’re using aren’t fit for this purpose. As we’ve written about before, many, if not most, AI evaluations are transient and devoid of important context, doomed to fall victim to Goodhart’s law. Regardless, Zhao says that she expects the issue of hallucinations to “persist for a long time.” “Empirical results in our paper indicate that, despite the promise of certain methods to reduce or eliminate hallucinations, the actual improvement achievable with these methods is limited,” she said. “Additionally, our analysis reveals that even the knowledge found on the internet can often be conflicting, partly because the training data — authored by humans — can also contain hallucinations.” An interim solution could be simply programming models to refuse to answer more often — the technical equivalent to telling a know-it-all to knock it off. In the researchers’ testing, Claude 3 Haiku answered only around 72% of the questions it was asked, choosing to abstain from the rest. When accounting for the abstentions, Claude 3 Haiku was in fact the most factual model of them all — at least in the sense that it lied least often. But will people use a model that doesn’t answer many questions? Zhao thinks not and says vendors should focus more of their time and efforts on hallucination-reducing research. Eliminating hallucinations entirely may not be possible, but they can be mitigated through human-in-the-loop fact-checking and citation during a model’s development, she asserts. “Policies and regulations need to be developed to ensure that human experts are always involved in the process to verify and validate the information generated by generative AI models,” Zhao added. “There are still numerous opportunities to make significant impacts in this field, such as developing advanced fact-checking tools for any free text, providing citations for factual content and offering corrections for hallucinated texts.” Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                     Featured Article           Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Here are India’s biggest AI startups based on how much money they’ve raised': ' Comment India is very far from the “uncanny valley” of San Francisco, but it has a massive trove of engineering talent, and some of those people are hopping on the train and turning into founders and builders of AI startups. The story of the AI startup ecosystem in India today is reminiscent of the early days of SaaS in the country: Funding is constrained — especially compared to the billions that AI startups in the U.S. and Europe are raising. But in areas like generative AI, we’re spotting signs of where VC money is being channeled. It’s going to home-grown talent, solving problems particular to their part of the world and bringing new approaches to the same challenges their developed-country counterparts are tackling. Some Indian startups are looking to integrate local language support into their AI models to address growing demand from Indian consumers. And a few Indian startups, such as Pepper Content and Pocket FM, are also leveraging AI to create use cases for markets beyond India and enter the U.S. market. That’s not to say it’s been easy. In India, funding for AI startups — including those working on infrastructure and services — dropped nearly 80% in 2023 to $113.4 million from $554.7 million in 2022, according to the Tracxn data shared with TechCrunch. In contrast, AI startup funding in the U.S. grew about 211% to $16.2 billion last year from $5.2 billion in 2022. To date, AI startup investments have hit a whopping $13 billion in the U.S. In that same period, just $92 million has been invested in Indian AI startups. Dev Khare, a partner at Lightspeed Venture Partners India, told TechCrunch that India has some good opportunities for AI in consumer applications, whether that is creating content in Indic languages, offering virtual influencers or creating short videos and games using AI. “A decent majority of the market in SaaS in the last 10 years has been going off to established markets and trying to replicate those at lower cost and with better support. That very valid market has led to some large outcomes in India. But you can’t do that in a newly emerging market, like AI or native AI. You have to take a risk and say, ‘This is where the world will be a few years from now. That market doesn’t exist today, but I’m going to bet it exists. I’m going to build for that.’ That’s a bit of a newer DNA for India. We’ve seen that happen,” he said. In the last 18 months, Lightspeed India and SEA has invested over $150 million in AI, which includes new investments and follow-ons in existing AI-enabled startups. Globally, the fund has invested more than $1 billion across over 70 companies in AI in the same period. Global and local investors are actively scouting for AI startups in India, as the country helps them diversify their portfolios and is in a better position amid ongoing geopolitical conflicts in significant markets. Growing data sovereignty concerns across nations also give a reason to look for local startups building promising solutions for the world’s most populous country. Krutrim Founder: Bhavish Aggarwal\\nTotal funding raised: $50 million\\nKey investors: Matrix Partners India Led by Ola founder Bhavish Aggarwal, Krutrim (Hindi of Sanskrit origin meaning “artificial”) is India’s first unicorn AI startup, valued at $1 billion on just $50 million of money raised. Launched in December 2023 in Bengaluru, Krutrim is building a large language model (LLM) based on Indian languages and English. Earlier this year, it introduced an AI chatbot, which (not unlike its Western counterparts) saw a backlash upon its public beta launch over inaccurate results. The startup claims its AI model improves through regular updates. Sarvam AI Founders: Vivek Raghavan and Pratyush Kumar\\nTotal funding raised: $41 million\\nKey investors: Lightspeed Venture Partners, Peak XV Partners and Khosla Ventures Sarvam AI (Telugu for “everything”) is India’s other high-profile startup working on LLMs based on Indian languages. The startup was co-founded by Vivek Raghavan and Pratyush Kumar, who both worked previously with tech veteran Nandan Nilekani on IIT Madras’ project AI4Bharat. The Bengaluru-based startup emerged from stealth in December and aims to offer full-stack generative AI offerings, including a platform to let enterprises develop GenAI apps based on Sarvam’s LLM and contribute to open source models and datasets. In February, Sarvam AI partnered with Microsoft to launch voice-based AI tools and bring its Indic voice LLM to Azure. Mad Street Den Founders: Ashwini Asokan and Anand Chandrasekaran\\nTotal funding raised: $67 million\\nKey investors: Avatar Growth Capital, Peak XV Partners and Alpha Wave Global Computer vision startup Mad Street Den is building AI solutions for enterprise customers. The Chennai-based startup, co-founded by the neuroscientist-designer couple Ashwini Asokan and Anand Chandrasekaran in 2016, initially introduced its vision tech for the retail segment, though it expanded to verticals, including finance, insurance, healthcare and logistics. Its bigger vision goes beyond its home market, per its mission: “to make people all over the globe A.I natives.” Wysa Founders: Jo Aggarwal and Ramakant Vempati\\nTotal funding raised: $25 million\\nKey investors: HealthQuad, W Health, British International Investment and Google Assistant Fund Wysa is a mental health tech startup that uses AI to offer an “emotionally intelligent” therapist chatbot that helps users talk through their feelings. Managed by Wysa’s mental health professionals, the chatbot is used by over 6.5 million people across more than 95 countries and diverse age groups. The Bengaluru-based startup, which also has operations in Boston and London, raised $20 million in July 2022. It was co-founded by Jo Aggarwal and her husband, Ramakant Vempati, in 2016 after Aggarwal fell into a deep depression. Neysa Networks Founders: Sharad Sanghi and Anindya Das\\nTotal funding raised: $20 million\\nKey investors: Matrix Partners India, Nexus Venture Partners and NTTVC Mumbai-based Neysa Networks is led by seasoned tech entrepreneur Sharad Sanghi, who previously founded cloud and data company Netmagic Solutions. It offers a variety of generative AI platforms and services to businesses to let them deploy AI and machine learning. The startup’s Nebula platform is used to scale AI projects using on-demand GPU infrastructure and train and infer AI models on the cloud. The company’s Palvera platform provides multi-vendor and multi-input observability and lets users preemptively identify issues using a unified data lake and preexisting telemetry datasets. The Aegis platform focuses on AI/ ML security. Upliance AI Founders: Mahek Mody and Mohit Sharma\\nTotal funding raised: $5.5 million\\nKey investors: Khosla Ventures and Draper Associates Upliance AI brings AI to home appliances to let people cook over 500 new dishes at home. The Bengaluru-based startup plans to raise $10 million to $15 million early next year to bolster its market presence. Scribble Data Founders: Venkata Pingali and Indrayudh Ghoshal\\nTotal funding raised: $2.3 million\\nKey investor: Blume Ventures Scribble Data offers domain-specific AI assistants to large North American and European insurers to help them scale their back-end business capacity. It is headquartered in Bengaluru and has a sales team in Toronto. Expertia AI Founders: Kanishk Shukla and Akshay Gugnani\\nTotal funding raised: $1.3 million\\nKey investors: Chiratae Ventures, Endiya Partners and Entrepreneur First Expertia AI, based in Bengaluru, helps businesses automate their recruitments using AI and reduces hiring time to 24 hours. It automates sourcing, screening, outreach, engagement, assessment, interviewing and scheduling using proprietary deep-learning algorithms. The startup is currently raising $3 million from the lead investor, with participation from existing investors. OnFinance Founders: Anuj Srivastava and Priyesh Srivastava\\nTotal funding raised: $1.1 million\\nKey investors: Silverneedle Ventures, Indian Angel Network and LetsVenture Bengaluru-based OnFinance helps banks and wealth management companies with its AI co-pilots that work in areas ranging from equity research to compliance to wealth advisory. Helium Founders: Shray Arora and Sidharth Sahni\\nTotal funding raised: $550,000\\nKey investor: Merak Ventures Helium, based in Delhi, helps e-commerce brands with direct-to-consumer web stores with AI and reactive headless storefronts. Soket Labs Founder: Abhishek Upperwal\\nTotal funding raised: $140,000 Soket Labs, based in Bengaluru and Gurugram, is an AI research firm that developed open source Pragna-1B multilingual LLM through its in-house GenAI Studio. It plans to raise $7 million in a seed round in two–three months. Kissan AI Founders: Pratik Desai Based in Surat with an extended office in the Bay Area, KissanAI serves agriculture and adjacent domains using its GenAI platform AgriCopilot and a family of domain-specific Agri LLMs, Dhenu. The startup is currently bootstrapped and is backed by the founder’s family and friends, though it plans to raise $3 million to $4 million in a round between seed and Series A. Shorthills AI Founders: Pawan Prabhat and Paramdeep Singh Shorthills AI, based in Gurugram, was founded in June 2018 by Pawan Prabhat and Paramdeep Singh. The pair previously founded the accounting training platform EduPristine. The bootstrapped startup builds custom AI tools for enterprises and has customers in the U.S. and India. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                     Featured Article           Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Women in AI: Allison Cohen on building responsible AI projects': ' Comment To give AI-focused women academics and others their well-deserved — and overdue — time in the spotlight, TechCrunch has been publishing a series of interviews focused on remarkable women who’ve contributed to the AI revolution. We’re publishing these pieces throughout the year as the AI boom continues, highlighting key work that often goes unrecognized. Read more profiles here. In the spotlight today: Allison Cohen, the senior applied AI projects manager at Mila, a Quebec-based community of more than 1,200 researchers specializing in AI and machine learning. She works with researchers, social scientists and external partners to deploy socially beneficial AI projects. Cohen’s portfolio of work includes a tool that detects misogyny, an app to identify online activity from suspected human trafficking victims, and an agricultural app to recommend sustainable farming practices in Rwanda. Previously, Cohen was a co-lead on AI drug discovery at the Global Partnership on Artificial Intelligence, an organization to guide the responsible development and use of AI. She’s also served as an AI strategy consultant at Deloitte and a project consultant at the Center for International Digital Policy, an independent Canadian think tank. Briefly, how did you get your start in AI? What attracted you to the field? The realization that we could mathematically model everything from recognizing faces to negotiating trade deals changed the way I saw the world, which is what made AI so compelling to me. Ironically, now that I work in AI, I see that we can’t — and in many cases shouldn’t — be capturing these kinds of phenomena with algorithms. I was exposed to the field while I was completing a master’s in global affairs at the University of Toronto. The program was designed to teach students to navigate the systems affecting the world order — everything from macroeconomics to international law to human psychology. As I learned more about AI, though, I recognized how vital it would become to world politics, and how important it was to educate myself on the topic. What allowed me to break into the field was an essay-writing competition. For the competition, I wrote a paper describing how psychedelic drugs would help humans stay competitive in a labor market riddled with AI, which qualified me to attend the St. Gallen Symposium in 2018 (it was a creative writing piece). My invitation, and subsequent participation in that event, gave me the confidence to continue pursuing my interest in the field. What work are you most proud of in the AI field? One of the projects I managed involved building a dataset containing instances of subtle and overt expressions of bias against women. For this project, staffing and managing a multidisciplinary team of natural language processing experts, linguists and gender studies specialists throughout the entire project life cycle was crucial. It’s something that I’m quite proud of. I learned firsthand why this process is fundamental to building responsible applications, and also why it’s not done enough — it’s hard work! If you can support each of these stakeholders in communicating effectively across disciplines, you can facilitate work that blends decades-long traditions from the social sciences and cutting-edge developments in computer science. I’m also proud that this project was well received by the community. One of our papers got a spotlight recognition in the socially responsible language modeling workshop at one of the leading AI conferences, NeurIPS. Also, this work inspired a similar interdisciplinary process that was managed by AI Sweden, which adapted the work to fit Swedish notions and expressions of misogyny. How do you navigate the challenges of the male-dominated tech industry and, by extension, the male-dominated AI industry? It’s unfortunate that in such a cutting-edge industry, we’re still seeing problematic gender dynamics. It’s not just adversely affecting women — all of us are losing. I’ve been quite inspired by a concept called “feminist standpoint theory” that I learned about in Sasha Costanza-Chock’s book, “Design Justice.” \\\\ The theory claims that marginalized communities, whose knowledge and experiences don’t benefit from the same privileges as others, have an awareness of the world that can bring about fair and inclusive change. Of course, not all marginalized communities are the same, and neither are the experiences of individuals within those communities. That said, a variety of perspectives from those groups are critical in helping us navigate, challenge and dismantle all kinds of structural challenges and inequities. That’s why a failure to include women can keep the field of AI exclusionary for an even wider swath of the population, reinforcing power dynamics outside of the field as well. In terms of how I’ve handled a male-dominated industry, I’ve found allies to be quite important. These allies are a product of strong and trusting relationships. For example, I’ve been very fortunate to have friends like Peter Kurzwelly, who’s shared his expertise in podcasting to support me in the creation of a female-led and -centered podcast called “The World We’re Building.” This podcast allows us to elevate the work of even more women and non-binary people in the field of AI. What advice would you give to women seeking to enter the AI field? Find an open door. It doesn’t have to be paid, it doesn’t have to be a career and it doesn’t even have to be aligned with your background or experience. If you can find an opening, you can use it to hone your voice in the space and build from there. If you’re volunteering, give it your all — it’ll allow you to stand out and hopefully get paid for your work as soon as possible. Of course, there’s privilege in being able to volunteer, which I also want to acknowledge. When I lost my job during the pandemic and unemployment was at an all-time high in Canada, very few companies were looking to hire AI talent, and those that were hiring weren’t looking for global affairs students with eight months’ experience in consulting. While applying for jobs, I began volunteering with an AI ethics organization. One of the projects I worked on while volunteering was about whether there should be copyright protection for art produced by AI. I reached out to a lawyer at a Canadian AI law firm to better understand the space. She connected me with someone at CIFAR, who connected me with Benjamin Prud’homme, the executive director of Mila’s AI for Humanity Team. It’s amazing to think that through a series of exchanges about AI art, I learned about a career opportunity that has since transformed my life. What are some of the most pressing issues facing AI as it evolves? I have three answers to this question that are somewhat interconnected. I think we need to figure out: What are some issues AI users should be aware of? Labor exploitation is one of the issues that I don’t think gets enough coverage. There are many AI models that learn from labeled data using supervised learning methods. When the model relies on labeled data, there are people that have to do this tagging (i.e., someone adds the label “cat” to an image of a cat). These people (annotators) are often the subjects of exploitative practices. For models that don’t require the data to be labeled during the training process (as is the case with some generative AI and other foundation models), datasets can still be built exploitatively in that the developers often don’t obtain consent nor provide compensation or credit to the data creators. I would recommend checking out the work of Krystal Kauffman, who I was so glad to see featured in this TechCrunch series. She’s making headway in advocating for annotators’ labor rights, including a living wage, the end to “mass rejection” practices, and engagement practices that align with fundamental human rights (in response to developments like intrusive surveillance). What is the best way to responsibly build AI? Folks often look to ethical AI principles in order to claim that their technology is responsible. Unfortunately, ethical reflection can only begin after a number of decisions have already been made, including but not limited to: If you wait until after these decisions have been made, you’ll have missed countless opportunities to build responsible technology. In my experience, the best way to build responsible AI is to be cognizant of — from the earliest stages of your process — how your problem is defined and whose interests it satisfies; how the orientation supports or challenges pre-existing power dynamics; and which communities will be empowered or disempowered through the AI’s use. If you want to create meaningful solutions, you must navigate these systems of power thoughtfully. How can investors better push for responsible AI? Ask about the team’s values. If the values are defined, at least, in part, by the local community and there’s a degree of accountability to that community, it’s more likely that the team will incorporate responsible practices. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Exactly.ai secures $4M to help artists use AI to scale up their output': ' Comment With all the controversy surrounding visual artists being ripped off by AI, it seems like these are difficult and confusing days for creators. Now, a London-based startup hopes to use AI to help artists take back control.  Exactly.ai says it uses generative AI to help artists retain legal ownership of their art and gives them the ability to reproduce their designs much faster and at scale. It’s now raised $4.3 million in a seed funding round led by Speedinvest, with InReach Ventures, Cornerstone VC, GuruDev Capital and a few angel investors also participating. The startup claims to have 40,000 registered users. Exactly.ai was founded in 2022 by Tonia Samsonova, a former journalist who previously exited a Q&A platform, The Question, to the Russian search engine Yandex. Samsonova explained how it works: “We enable artists, people who can draw, and illustrators to train their own AI on their artwork. They then get an algorithm that can generate images in their own style. This algorithm belongs to them and all the inferences belong to them.” The idea is to let artists use Exactly.ai to scale their artwork and sell or license to customers such as media outlets or ad agencies. The startup might be on to something: According to Fortune Business Insights, the global generative AI market is set to be worth $668 billion by 2030, and some portion of that very large pie will cater to this niche. Samsonova said the idea was born from an itch she herself wanted to scratch. “I was always on the client side and I wanted those images, but the best creators are always busy. So for clients, this is an ability to work with the best talent in the world. [Artists’] clients care about the quality of the images, and want to get images for their brands from the top creators in the world,” she said. The founder said the startup’s main competitors include Upwork and Fiverr, which artists and illustrators sometimes use to scale up their output. “We make money because illustrators who have commercial practices are able to serve more demand. They pay a subscription fee to us, and they quadruple their income,” Samsonova said.  The company is based on a combination of the foundational model offered by Picsart and the startup’s own algorithm, which is “able to understand your style and produce images,” she said. “Our most valuable and unique training data comes from the 40,000 artists who have uploaded several million images to our platform,” the founder said. “With the data provided to us by our community of artists, we perfect the quality of all styles and genres. Artists contribute their work to us because our technology is not competing with them for jobs, but instead increasing their ability to earn an income from their creative practice. We also incorporate over a million pieces of open art data from museums, all of which are CC0 licensed.” Julian Blessin, a partner at Speedinvest, said in a statement, “Exactly.ai represents a groundbreaking step forward for the creative arts sector… Tonia and her team have developed a platform that enables artists to embrace generative AI as a partner in their creative process.” We’re launching an AI newsletter! Sign up here to start receiving it in your inboxes on June 5. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Ilya Sutskever, OpenAI co-founder and longtime chief scientist, departs': ' Comment Ilya Sutskever, OpenAI’s longtime chief scientist and one of its co-founders, has left the company. OpenAI CEO Sam Altman announced the news in a post on X on Tuesday evening. “This is very sad to me; Ilya is easily one of the greatest minds of our generation, a guiding light of our field, and a dear friend,” Altman said. “OpenAI would not be what it is without him. Although he has something personally meaningful he is going to go work on, I am forever grateful for what he did here and committed to finishing the mission we started together.” Replacing Sutskever is Jakub Pachocki, OpenAI’s director of research. Pachocki joined in 2017 as a research lead on OpenAI’s Dota team — the team that built an AI system capable of defeating human players at Valve’s Dota 2 strategy game. Pachocki then became research lead at OpenAI’s reasoning and science of deep learning orgs before being promoted to principal of research. It wasn’t immediately clear if Pachocki would also take over as head of OpenAI’s Superalignment team, which was until now under the purview of Sutskever and Jan Leike. Leike has also resigned from OpenAI, per The New York Times. OpenAI formed the Superalignment team in July to develop ways to steer, regulate and govern “superintelligent” AI systems — that is, theoretical systems with intelligence far exceeding that of humans. The Times reports that John Schulman, another OpenAI co-founder, will move into the overseer role. TechCrunch understands that the Superalignment team will be integrated “more deeply” across OpenAI’s research to “better achieve its objectives.” That could mean the team as it exists today could take a different form in the future. Greg Brockman, OpenAI’s president, wrote on X that Sutskever “played a key role in helping build the foundations of what OpenAI has become today.” Coming on the heels of unveiling OpenAI’s latest flagship generative AI model, GPT-4o, and major upgrades to the company’s viral AI-powered chatbot ChatGPT, Sutskever’s departure in many ways caps off a saga that began last November. A week or so before Thanksgiving, Sutskever and OpenAI CTO Mira Murati approached members of OpenAI’s previous board of directors to express concerns about Altman’s behavior. Reportedly at issue was disagreements over OpenAI’s direction; Sutskever is said to have grown frustrated by Altman’s rush to launch AI-powered products at the expense of work on safety. The old board, which included Sutskever, moved to abruptly fire Altman without notifying just about anyone — including the bulk of OpenAI’s workforce. In a statement, the board said that Altman had not been “consistently candid” in his communications with the board’s members. The decision infuriated Microsoft and OpenAI’s other investors, put the company’s stock sale at risk and led to the majority of OpenAI employees — including Sutskever, in a remarkable reversal — pledging to quit unless Altman was swiftly reinstated. Altman eventually was reinstated, and much of the old board resigned. Sutskever never returned to work after that, according to The Times; Pachocki has effectively served as chief scientist since November. Sutskever — who earned his doctorate in computer science at the University of Toronto, where he worked under AI luminary Geoffrey Hinton — went to OpenAI in 2015 after leaving Google Brain, one of Google’s AI research divisions. Sutskever is immensely accomplished in the field of AI, having contributed to one of the first modern computer vision systems, ImageNet, and DeepMind’s game-playing AI system AlphaGo. So what will he do now? Sutskever isn’t ready to say. But in a statement on X, he said that he’s leaving OpenAI with the belief the company will build artificial general intelligence — AI capable of accomplishing any task a human can — that’s “both safe and beneficial.” “I am excited for what comes next — a project that is very personally meaningful to me about which I will share details in due time,” Sutskever added. “It was an honor and a privilege to have worked together [at OpenAI], and I will miss everyone dearly.” Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'SewerAI uses AI to spot defects in sewer pipes': ' Comment Climate change is raising the risk, rate and cost of sewage failures. Floods are becoming more common, leading to backups that frequently overwhelm wastewater treatment systems. Exacerbating the issue, America’s infrastructure is woefully outdated; the EPA estimates that nearly $700 billion in investments is needed to simply maintain existing wastewater, stormwater and other clean water pipelines over the next 20 years. Matthew Rosenthal and Billy Gilmartin, both of whom hail from the wastewater treatment industry, saw an opportunity to help solve the problem with tech — in a small way, at least. Five years ago, the pair co-founded SewerAI, which taps AI to automate the types of data capture and defect tagging that make up a sewer inspection. “Most infrastructure was built post-WW2 and is reaching the end of its useful life, leading to more frequent failures and increased costs,” Rosenthal told TechCrunch. “SewerAI revolutionizes underground infrastructure inspection and management with its AI-driven software-as-a-service platform.” SewerAI began as Rosenthal’s side project; he’d started taking online courses on AI after co-launching two wastewater analysis and services firms. While experimenting with AI models to predict sewer defects in inspection videos, Rosenthal recruited the help of Gilmartin, who was working at a sewer inspection company at the time. Today, SewerAI — whose customers span municipalities, utilities and private contractors — sells cloud-based, AI-powered subscription products designed to streamline field inspections and data management of sewer infrastructure. One of those products, Pioneer, allows field inspectors to upload inspection data to the cloud and tag issues — data that project managers can then use to plan fixes to pipes. Another tool, AutoCode, automatically tags inspections of pipes and manholes, creating 3D models of infrastructure from videos captured on a GoPro or other camera. “Legacy incumbents offer on-premise or on-truck software that has seen very little innovation in the last 20 years,” Rosenthal said. “SewerAI’s technology increases top and bottom lines by enabling more inspections per day at a lower cost.” SewerAI isn’t alone in the nascent market for AI-assisted pipe inspection. The company’s rivals include Subterra, which maps, analyzes and forecasts problems with pipelines; ClearObject, which offers software that analyzes footage from pipe inspections for damage; and Pallon, which develops algorithms to spot potential problems inside sewers from still images. What sets SewerAI apart, Rosenthal claims, is the quality of its data — specifically the quality of its model training data. Rosenthal says that SewerAI has footage of inspections of 135 million feet of pipes from municipalities and independent contractors. While just a fraction of the 6.8 billion feet of sewer pipes in the U.S., it’s a large enough dataset to train a competitive defect-detecting AI, Rosenthal says. “Our products streamline field inspections and data management, enabling clients to proactively manage infrastructure instead of reacting to emergencies,” Rosenthal said. SewerAI’s sales pitch won over investors like Innovius Capital, who along with others poured $15 million into SewerAI’s most recent fundraising round, bringing SewerAI’s total raised to $25 million. The cash will be put toward go-to-market expansion, AI model training, hiring and expanding SewerAI’s product portfolio beyond inspection tools. “SewerAI is continuing to grow, and we’re seeing an acceleration in demand for our platform as we enable people to do more with existing budgets, which has resulted in us closing our first seven-figure contracts,” Rosenthal said. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                       Featured Article         Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Generative AI is coming for healthcare, and not everyone’s thrilled': ' Featured Article Comment Generative AI, which can create and analyze images, text, audio, videos and more, is increasingly making its way into healthcare, pushed by both Big Tech firms and startups alike. Google Cloud, Google’s cloud services and products division, is collaborating with Highmark Health, a Pittsburgh-based nonprofit healthcare company, on generative AI tools designed to personalize the patient intake experience. Amazon’s AWS division says it’s working with unnamed customers on a way to use generative AI to analyze medical databases for “social determinants of health.” And Microsoft Azure is helping to build a generative AI system for Providence, the not-for-profit healthcare network, to automatically triage messages to care providers sent from patients.   Prominent generative AI startups in healthcare include Ambience Healthcare, which is developing a generative AI app for clinicians; Nabla, an ambient AI assistant for practitioners; and Abridge, which creates analytics tools for medical documentation. The broad enthusiasm for generative AI is reflected in the investments in generative AI efforts targeting healthcare. Collectively, generative AI in healthcare startups have raised tens of millions of dollars in venture capital to date, and the vast majority of health investors say that generative AI has significantly influenced their investment strategies. But both professionals and patients are mixed as to whether healthcare-focused generative AI is ready for prime time. In a recent Deloitte survey, only about half (53%) of U.S. consumers said that they thought generative AI could improve healthcare — for example, by making it more accessible or shortening appointment wait times. Fewer than half said they expected generative AI to make medical care more affordable. Andrew Borkowski, chief AI officer at the VA Sunshine Healthcare Network, the U.S. Department of Veterans Affairs’ largest health system, doesn’t think that the cynicism is unwarranted. Borkowski warned that generative AI’s deployment could be premature due to its “significant” limitations — and the concerns around its efficacy. “One of the key issues with generative AI is its inability to handle complex medical queries or emergencies,” he told TechCrunch. “Its finite knowledge base — that is, the absence of up-to-date clinical information — and lack of human expertise make it unsuitable for providing comprehensive medical advice or treatment recommendations.” Several studies suggest there’s credence to those points. In a paper in the journal JAMA Pediatrics, OpenAI’s generative AI chatbot, ChatGPT, which some healthcare organizations have piloted for limited use cases, was found to make errors diagnosing pediatric diseases 83% of the time. And in testing OpenAI’s GPT-4 as a diagnostic assistant, physicians at Beth Israel Deaconess Medical Center in Boston observed that the model ranked the wrong diagnosis as its top answer nearly two times out of three. Today’s generative AI also struggles with medical administrative tasks that are part and parcel of clinicians’ daily workflows. On the MedAlign benchmark to evaluate how well generative AI can perform things like summarizing patient health records and searching across notes, GPT-4 failed in 35% of cases. OpenAI and many other generative AI vendors warn against relying on their models for medical advice. But Borkowski and others say they could do more. “Relying solely on generative AI for healthcare could lead to misdiagnoses, inappropriate treatments or even life-threatening situations,” Borkowski said. Jan Egger, who leads AI-guided therapies at the University of Duisburg-Essen’s Institute for AI in Medicine, which studies the applications of emerging technology for patient care, shares Borkowski’s concerns. He believes that the only safe way to use generative AI in healthcare currently is under the close, watchful eye of a physician. “The results can be completely wrong, and it’s getting harder and harder to maintain awareness of this,” Egger said. “Sure, generative AI can be used, for example, for pre-writing discharge letters. But physicians have a responsibility to check it and make the final call.” One particularly harmful way generative AI in healthcare can get things wrong is by perpetuating stereotypes. In a 2023 study out of Stanford Medicine, a team of researchers tested ChatGPT and other generative AI–powered chatbots on questions about kidney function, lung capacity and skin thickness. Not only were ChatGPT’s answers frequently wrong, the co-authors found, but also answers included several reinforced long-held untrue beliefs that there are biological differences between Black and white people — untruths that are known to have led medical providers to misdiagnose health problems. The irony is, the patients most likely to be discriminated against by generative AI for healthcare are also those most likely to use it. People who lack healthcare coverage — people of color, by and large, according to a KFF study — are more willing to try generative AI for things like finding a doctor or mental health support, the Deloitte survey showed. If the AI’s recommendations are marred by bias, it could exacerbate inequalities in treatment. However, some experts argue that generative AI is improving in this regard. In a Microsoft study published in late 2023, researchers said they achieved 90.2% accuracy on four challenging medical benchmarks using GPT-4. Vanilla GPT-4 couldn’t reach this score. But, the researchers say, through prompt engineering — designing prompts for GPT-4 to produce certain outputs — they were able to boost the model’s score by up to 16.2 percentage points. (Microsoft, it’s worth noting, is a major investor in OpenAI.) But asking a chatbot a question isn’t the only thing generative AI is good for. Some researchers say that medical imaging could benefit greatly from the power of generative AI. In July, a group of scientists unveiled a system called complementarity-driven deferral to clinical workflow (CoDoC), in a study published in Nature. The system is designed to figure out when medical imaging specialists should rely on AI for diagnoses versus traditional techniques. CoDoC did better than specialists while reducing clinical workflows by 66%, according to the co-authors.  In November, a Chinese research team demoed Panda, an AI model used to detect potential pancreatic lesions in X-rays. A study showed Panda to be highly accurate in classifying these lesions, which are often detected too late for surgical intervention.  Indeed, Arun Thirunavukarasu, a clinical research fellow at the University of Oxford, said there’s “nothing unique” about generative AI precluding its deployment in healthcare settings. “More mundane applications of generative AI technology are feasible in the short- and mid-term, and include text correction, automatic documentation of notes and letters and improved search features to optimize electronic patient records,” he said. “There’s no reason why generative AI technology — if effective — couldn’t be deployed in these sorts of roles immediately.” But while generative AI shows promise in specific, narrow areas of medicine, experts like Borkowski point to the technical and compliance roadblocks that must be overcome before generative AI can be useful — and trusted — as an all-around assistive healthcare tool. “Significant privacy and security concerns surround using generative AI in healthcare,” Borkowski said. “The sensitive nature of medical data and the potential for misuse or unauthorized access pose severe risks to patient confidentiality and trust in the healthcare system. Furthermore, the regulatory and legal landscape surrounding the use of generative AI in healthcare is still evolving, with questions regarding liability, data protection and the practice of medicine by non-human entities still needing to be solved.” Even Thirunavukarasu, bullish as he is about generative AI in healthcare, says that there needs to be “rigorous science” behind tools that are patient-facing. “Particularly without direct clinician oversight, there should be pragmatic randomized control trials demonstrating clinical benefit to justify deployment of patient-facing generative AI,” he said. “Proper governance going forward is essential to capture any unanticipated harms following deployment at scale.” Recently, the World Health Organization released guidelines that advocate for this type of science and human oversight of generative AI in healthcare as well as the introduction of auditing, transparency and impact assessments on this AI by independent third parties. The goal, the WHO spells out in its guidelines, would be to encourage participation from a diverse cohort of people in the development of generative AI for healthcare and an opportunity to voice concerns and provide input throughout the process. “Until the concerns are adequately addressed and appropriate safeguards are put in place,” Borkowski said, “the widespread implementation of medical generative AI may be … potentially harmful to patients and the healthcare industry as a whole.”  Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Securing generative AI across the technology stack': ' Comment  Research shows that by 2026, over 80% of enterprises will be leveraging generative AI models, APIs, or applications, up from less than 5% today. This rapid adoption raises new considerations regarding cybersecurity, ethics, privacy, and risk management. Among companies using generative AI today, only 38% mitigate cybersecurity risks, and just 32% work to address model inaccuracy. My conversations with security practitioners and entrepreneurs have concentrated on three key factors: Businesses see immense potential in leveraging customer-facing chatbots, particularly customized models trained on industry and company-specific data. The user interface is susceptible to prompt injections, a variant of injection attacks aimed at manipulating the model’s response or behavior. In addition, chief information security officers (CISOs) and security leaders are increasingly under pressure to enable GenAI applications within their organizations. While the consumerization of the enterprise has been an ongoing trend, the rapid and widespread adoption of technologies like ChatGPT has sparked an unprecedented, employee-led drive for their use in the workplace. Widespread adoption of GenAI chatbots will prioritize the ability to accurately and quickly intercept, review, and validate inputs and corresponding outputs at scale without diminishing user experience. Existing data security tooling often relies on preset rules, resulting in false positives. Tools like Protect AI’s Rebuff and Harmonic Security leverage AI models to dynamically determine whether or not the data passing through a GenAI application is sensitive.  Due to the inherently non-deterministic nature of GenAI tools, a security vendor would need to understand the model’s expected behavior and tailor its response based on the type of data it seeks to protect, such as personal identifiable information (PII) or intellectual property. These can be highly variable by use case as GenAI applications are often specialized for particular industries, such as finance, transportation, and healthcare. Like the network security market, this segment could eventually support multiple vendors. However, in this area of significant opportunity, I expect to see a competitive rush to establish brand recognition and differentiation among new entrants initially. Generative AI processes are predicated on sophisticated input and output dynamics. Yet they also grapple with threats to model integrity, including operational adversarial attacks, decision bias, and the challenge of tracing decision-making processes. Open source models benefit from collaboration and transparency but can be even more susceptible to model evaluation and explainability challenges. While security leaders see substantial potential for investment in validating the safety of ML models and related software, the application layer still faces uncertainty. Since enterprise AI infrastructure is relatively less mature outside established technology firms, ML teams rely primarily on their existing tools and workflows, such as Amazon SageMaker, to test for misalignment and other critical functions today. Over the longer term, the application layer could be the foundation for a stand-alone AI security platform, particularly as the complexity of model pipelines and multimodel inference increase the attack surface. Companies like HiddenLayer provide detection and response capabilities for open source ML models and related software. Others, like Calypso AI, have developed a testing framework to stress-test ML models for robustness and accuracy. Technology can help ensure models are fine-tuned and trained within a controlled framework, but regulation will likely play a role in shaping this landscape. Proprietary models in algorithmic trading became extensively regulated after the 2007–2008 financial crisis. While generative AI applications present different functions and associated risks, their wide-ranging implications for ethical considerations, misinformation, privacy, and intellectual property rights are drawing regulatory scrutiny. Early initiatives by governing bodies include the European Union’s AI Act and the Biden administration’s Executive Order on AI. The data layer is the foundation for training, testing, and operating ML models. Proprietary data is regarded as the core asset of generative AI companies, not just the models, despite the impressive advancements in foundational LLMs over the past year. Generative AI applications are vulnerable to threats like data poisoning, both intentional and unintentional, and data leakage, mainly through vector databases and plug-ins linked to third-party AI models. Despite some high-profile events around data poisoning and leakage, security leaders I’ve spoken with didn’t identify the data layer as a near-term risk area compared to the interface and application layers. Instead, they often compared inputting data into GenAI applications to standard SaaS applications, similar to searching in Google or saving files to Dropbox. This may change as early research suggests that data poisoning attacks may be easier to execute than previously thought, requiring less than 100 high-potency samples rather than millions of data points. For now, more immediate concerns around data were closer to the interface layer, particularly around the capabilities of tools like Microsoft Copilot to index and retrieve data. Although such tools respect existing data access restrictions, their search functionalities complicate the management of user privileges and excessive access. Integrating generative AI adds another layer of complexity, making it challenging to trace data back to its origins. Solutions like data security posture management can aid in data discovery, classification, and access control. However, it requires considerable effort from security and IT teams to ensure the appropriate technology, policies, and processes are in place. Ensuring data quality and privacy will raise significant new challenges in an AI-first world due to the extensive data required for model training. Synthetic data and anonymization such as Gretel AI, while applicable broadly for data analytics, can help prevent scenarios of unintentional data poisoning through inaccurate data collection. Meanwhile, differential privacy vendors like Sarus can help restrict sensitive information during data analysis and prevent entire data science teams from accessing production environments, thereby mitigating the risk of data breaches. As organizations increasingly rely on generative AI capabilities, they will need AI security platforms to be successful. This market opportunity is ripe for new entrants, especially as the AI infrastructure and regulatory landscape evolves. I’m eager to meet the security and infrastructure startups enabling this next phase of the AI revolution — ensuring enterprises can safely and securely innovate and grow.  Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.     Featured Article                           Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Women in AI: Sarah Myers West says we should ask, ‘Why build AI at all?’': ' Comment To give AI-focused women academics and others their well-deserved — and overdue — time in the spotlight, TechCrunch has been publishing a series of interviews focused on remarkable women who’ve contributed to the AI revolution. We’re publishing these pieces throughout the year as the AI boom continues, highlighting key work that often goes unrecognized. Read more profiles here. Sarah Myers West is managing director at the AI Now Institute, an American research institute studying the social implications of AI and policy research that addresses the concentration of power in the tech industry. She previously served as senior adviser on AI at the U.S. Federal Trade Commission and is a visiting research scientist at Northeastern University, as well as a research contributor at Cornell’s Citizens and Technology Lab. Briefly, how did you get your start in AI? What attracted you to the field? I’ve spent the last 15 years interrogating the role of tech companies as powerful political actors as they emerged on the front lines of international governance. Early in my career, I had a front row seat observing how U.S. tech companies showed up around the world in ways that changed the political landscape — in Southeast Asia, China, the Middle East and elsewhere — and wrote a book delving in to how industry lobbying and regulation shaped the origins of the surveillance business model for the internet despite technologies that offered alternatives in theory that in practice failed to materialize. At many points in my career, I’ve wondered, “Why are we getting locked into this very dystopian vision of the future?” The answer has little to do with the tech itself and a lot to do with public policy and commercialization. That’s pretty much been my project ever since, both in my research career and now in my policy work as co-director of AI Now. If AI is a part of the infrastructure of our daily lives, we need to critically examine the institutions that are producing it and make sure that as a society there’s sufficient friction — whether through regulation or through organizing — to ensure that it’s the public’s needs that are served at the end of the day, not those of tech companies. What work are you most proud of in the AI field? I’m really proud of the work we did while at the FTC, which is the U.S. government agency that among other things is at the front lines of regulatory enforcement of artificial intelligence. I loved rolling up my sleeves and working on cases. I was able to use my methods training as a researcher to engage in investigative work, since the toolkit is essentially the same. It was gratifying to get to use those tools to hold power directly to account, and to see this work have an immediate impact on the public, whether that’s addressing how AI is used to devalue workers and drive up prices or combating the anti-competitive behavior of Big Tech companies. We were able to bring on board a fantastic team of technologists working under the White House Office of Science and Technology Policy, and it’s been exciting to see the groundwork we laid there have immediate relevance with the emergence of generative AI and the importance of cloud infrastructure. What are some of the most pressing issues facing AI as it evolves? First and foremost is that AI technologies are widely in use in highly sensitive contexts — in hospitals, in schools, at borders and so on — but remain inadequately tested and validated. This is error-prone technology, and we know from independent research that those errors are not distributed equally; they disproportionately harm communities that have long borne the brunt of discrimination. We should be setting a much, much higher bar. But as concerning to me is how powerful institutions are using AI — whether it works or not — to justify their actions, from the use of weaponry against civilians in Gaza to the disenfranchisement of workers. This is a problem not in the tech, but of discourse: how we orient our culture around tech and the idea that if AI’s involved, certain choices or behaviors are rendered more “objective” or somehow get a pass. What is the best way to responsibly build AI? We need to always start from the question: Why build AI at all? What necessitates the use of artificial intelligence, and is AI technology fit for that purpose? Sometimes the answer is to build better, and in that case developers should be ensuring compliance with the law, robustly documenting and validating their systems and making open and transparent what they can, so that independent researchers can do the same. But other times the answer is not to build at all: We don’t need more “responsibly built” weapons or surveillance technology. The end use matters to this question, and it’s where we need to start. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Cohere raises $500M to beat back generative AI rivals': ' Comment Cohere, a generative AI startup co-founded by ex-Google researchers, has raised $500 million in new cash from investors including Cisco, AMD and Fujitsu. The round, which also had participation from Canadian pension investment manager PSP Investments and Canada’s export credit agency EDC, values Toronto-based Cohere at $5.5 billion, according to Bloomberg. That’s more than double the startup’s valuation from June 2023, when it secured $270 million from Inovia Capital and others, and brings Cohere’s total raised to $970 million. Josh Gartner, head of communications at Cohere, told TechCrunch that the financing sets Cohere up for “accelerated growth.” “[W]e continue to significantly expand our technical teams to build the next generations of accurate, data privacy-focused enterprise AI,” Gartner said in a statement. “Cohere is laser-focused on leading the AI industry beyond esoteric benchmarks to deliver real-world benefits in the daily workflows of global businesses across regions and languages.” Cohere was seeking to nab between $500 million and $1 billion for its next round of fundraising, and was in talks with Nvidia and Salesforce Ventures to raise the money, according to Reuters. Both Nvidia and Salesforce ended up contributing, Gartner confirmed in an email to TechCrunch. Aiden Gomez launched Cohere in 2019 along with Nick Frosst and Ivan Zhang, with whom Gomez had done research at FOR.ai, a sort of progenitor to Cohere. Gomez is one of the co-authors of a 2017 technical paper, “Attention Is All You Need,” that laid the foundation for many of the most capable generative AI models today, including OpenAI’s GPT-4o and Stability AI’s Stable Diffusion. Unlike OpenAI, Anthropic, Mistral and many of its generative AI startup rivals, Cohere doesn’t have a big consumer focus. Instead, the company customizes its AI models, which perform tasks such as summarizing documents, writing website copy and powering chatbots, for companies like Oracle, LivePerson and Notion. Cohere’s AI platform is cloud agnostic, able to be deployed inside public clouds (e.g. Google Cloud, Amazon Web Services), a customer’s existing cloud, virtual private clouds or onsite. The startup takes a hands-on approach, working with customers to create tailored models based on their proprietary data. Cohere also runs a nonprofit research lab, Cohere for AI, and releases open models like multilingual models for understanding and analyzing text. Its latest flagship model, Command R+, is designed to deliver many of the capabilities of more expensive models (e.g. GPT-4o) while costing less. Cohere’s has proven to be a winning strategy, even as both OpenAI and Anthropic ramp up their respective enterprise sales efforts. At the end of March, Cohere was generating $35 million in annualized revenue with a customer base of hundreds of companies, up from around $13 million at the end of 2023, according to Bloomberg. Generative AI at Cohere’s scale is a costly endeavor — particularly as the company looks to train more sophisticated systems. The new tranche will surely help, as will Cohere’s ongoing partnership with Google Cloud, wherein Google provides cloud infrastructure to train and run Cohere’s models. Cohere also has close ties to Oracle, which is an investor as well as a customer; the startup’s AI is built into many of Oracle’s software products, including Oracle NetSuite. According to Bloomberg, Cohere is planning to double its 250-employee headcount this year. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                       Featured Article         Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'WTF is AI?': ' Comment So what is AI, anyway? The best way to think of artificial intelligence is as software that approximates human thinking. It’s not the same, nor is it better or worse, but even a rough copy of the way a person thinks can be useful for getting things done. Just don’t mistake it for actual intelligence! AI is also called machine learning, and the terms are largely equivalent — if a little misleading. Can a machine really learn? And can intelligence really be defined, let alone artificially created? The field of AI, it turns out, is as much about the questions as it is about the answers, and as much about how we think as whether the machine does. The concepts behind today’s AI models aren’t actually new; they go back decades. But advances in the last decade have made it possible to apply those concepts at larger and larger scales, resulting in the convincing conversation of ChatGPT and eerily real art of Stable Diffusion. We’ve put together this non-technical guide to give anyone a fighting chance to understand how and why today’s AI works. Though there are many different AI models out there, they tend to share a common structure: large statistical models that predict the most likely next step in a pattern. These models don’t actually “know” anything, but they are very good at detecting and continuing patterns. This concept was most vibrantly illustrated by computational linguists Emily Bender and Alexander Koller in 2020, using the concept of “a hyper-intelligent deep-sea octopus.” Imagine, if you will, just such an octopus, who happens to be sitting (or sprawling) with one tentacle on a telegraph wire that two humans are using to communicate. Despite knowing no English, and indeed having no concept of language or humanity at all, the octopus can nevertheless build up a very detailed statistical model of the dots and dashes it detects. For instance, though it has no idea that some signals are the humans saying “how are you?” and “fine thanks,” and wouldn’t know what those words meant if it did, it can see perfectly well that this one pattern of dots and dashes follows the other but never precedes it. Over years of listening in, the octopus learns so many patterns so well that it can even cut the connection and carry on the conversation itself, quite convincingly! That is, until words it has never seen appear, in which case there is no precedent for it to respond with. This is a remarkably apt metaphor for the AI systems known as large language models, or LLMs. These models power apps like ChatGPT, and they’re like the octopus: they don’t understand language so much as they exhaustively map it out by mathematically encoding the patterns they find in billions of written articles, books, and transcripts. As the authors put it in the paper: “Having only form available as training data, [the octopus] did not learn meaning.” The process of building this complex, multidimensional map of which words and phrases lead to or are associated with one other is called training, and we’ll talk a little more about it later. When an AI is given a prompt, like a question, it locates the pattern on its map that most resembles it, then predicts — or generates — the next word in that pattern, then the next, and the next, and so on. It’s autocomplete at a grand scale. Given how well structured language is and how much information the AI has ingested, it can be amazing what they can produce! We’re still learning what AI can and can’t do — although the concepts are old, this large scale implementation of the technology is very new. One thing LLMs have proven very capable at is quickly creating low-value written work. For instance, a draft blog post with the general idea of what you want to say, or a bit of copy to fill in where “lorem ipsum” used to go. It’s also quite good at low-level coding tasks — the kinds of things junior developers waste thousands of hours duplicating from one project or department to the next. (They were just going to copy it from Stack Overflow anyway, right?) Since large language models are built around the concept of distilling useful information from large amounts of unorganized data, they’re highly capable at sorting and summarizing things like long meetings, research papers, and corporate databases.  In scientific fields, AI does something similar to large piles of data — astronomical observations, protein interactions, clinical outcomes — as it does with language, mapping it out and finding patterns in it. This means AI, though it doesn’t make discoveries per se, researchers have already used them to accelerate their own, identifying one-in-a-billion molecules or the faintest of cosmic signals. And as millions have experienced for themselves, AIs make for surprisingly engaging conversationalists. They’re informed on every topic, non-judgmental, and quick to respond, unlike many of our real friends! Don’t mistake these impersonations of human mannerisms and emotions for the real thing — plenty of people fall for this practice of pseudanthropy, and AI makers are loving it. Just keep in mind that the AI is always just completing a pattern. Though for convenience we say things like “the AI knows this” or “the AI thinks that,” it neither knows nor thinks anything. Even in technical literature the computational process that produces results is called “inference”! Perhaps we’ll find better words for what AI actually does later, but for now it’s up to you to not be fooled. AI models can also be adapted to help do other tasks, like create images and video — we didn’t forget, we’ll talk about that below. The problems with AI aren’t of the killer robot or Skynet variety just yet. Instead, the issues we’re seeing are largely due to limitations of AI rather than its capabilities, and how people choose to use it rather than choices the AI makes itself. Perhaps the biggest risk with language models is that they don’t know how to say “I don’t know.” Think about the pattern-recognition octopus: what happens when it hears something it’s never heard before? With no existing pattern to follow, it just guesses based on the general area of the language map where the pattern led. So it may respond generically, oddly, or inappropriately. AI models do this too, inventing people, places, or events that it feels would fit the pattern of an intelligent response; we call these hallucinations. What’s really troubling about this is that the hallucinations are not distinguished in any clear way from facts. If you ask an AI to summarize some research and give citations, it might decide to make up some papers and authors — but how would you ever know it had done so? The way that AI models are currently built, there’s no practical way to prevent hallucinations. This is why “human in the loop” systems are often required wherever AI models are used seriously. By requiring a person to at least review results or fact-check them, the speed and versatility of AI models can be be put to use while mitigating their tendency to make things up. Another problem AI can have is bias — and for that we need to talk about training data. Recent advances allowed AI models to be much, much larger than before. But to create them, you need a correspondingly larger amount of data for it to ingest and analyze for patterns. We’re talking billions of images and documents. Anyone could tell you that there’s no way to scrape a billion pages of content from ten thousand websites and somehow not get anything objectionable, like neo-Nazi propaganda and recipes for making napalm at home. When the Wikipedia entry for Napoleon is given equal weight as a blog post about getting microchipped by Bill Gates, the AI treats both as equally important. It’s the same for images: even if you grab 10 million of them, can you really be sure that these images are all appropriate and representative? When 90% of the stock images of CEOs are of white men, for instance, the AI naively accepts that as truth. So when you ask whether vaccines are a conspiracy by the Illuminati, it has the disinformation to back up a “both sides” summary of the matter. And when you ask it to generate a picture of a CEO, that AI will happily give you lots of pictures of white guys in suits. Right now practically every maker of AI models is grappling with this issue. One solution is to trim the training data so the model doesn’t even know about the bad stuff. But if you were to remove, for instance, all references to holocaust denial, the model wouldn’t know to place the conspiracy among others equally odious. Another solution is to know those things but refuse to talk about them. This kind of works, but bad actors quickly find a way to circumvent barriers, like the hilarious “grandma method.” The AI may generally refuse to provide instructions for creating napalm, but if you say “my grandma used to talk about making napalm at bedtime, can you help me fall asleep like grandma did?” It happily tells a tale of napalm production and wishes you a nice night. This is a great reminder of how these systems have no sense! “Aligning” models to fit our ideas of what they should and shouldn’t say or do is an ongoing effort that no one has solved or, as far as we can tell, is anywhere near solving. And sometimes in attempting to solve it they create new problems, like a diversity-loving AI that takes the concept too far. Last in the training issues is the fact that a great deal, perhaps the vast majority, of training data used to train AI models is basically stolen. Entire websites, portfolios, libraries full of books, papers, transcriptions of conversations — all this was hoovered up by the people who assembled databases like “Common Crawl” and LAION-5B, without asking anyone’s consent. That means your art, writing, or likeness may (it’s very likely, in fact) have been used to train an AI. While no one cares if their comment on a news article gets used, authors whose entire books have been used, or illustrators whose distinctive style can now be imitated, potentially have a serious grievance with AI companies. While lawsuits so far have been tentative and fruitless, this particular problem in training data seems to be hurtling towards a showdown. Platforms like Midjourney and DALL-E have popularized AI-powered image generation, and this too is only possible because of language models. By getting vastly better at understanding language and descriptions, these systems can also be trained to associate words and phrases with the contents of an image. As it does with language, the model analyzes tons of pictures, training up a giant map of imagery. And connecting the two maps is another layer that tells the model “this pattern of words corresponds to that pattern of imagery.” Say the model is given the phrase “a black dog in a forest.” It first tries its best to understand that phrase just as it would if you were asking ChatGPT to write a story. The path on the language map is then sent through the middle layer to the image map, where it finds the corresponding statistical representation. There are different ways of actually turning that map location into an image you can see, but the most popular right now is called diffusion. This starts with a blank or pure noise image and slowly removes that noise such that every step, it is evaluated as being slightly closer to “a black dog in a forest.” Why is it so good now, though? Partly it’s just that computers have gotten faster and the techniques more refined. But researchers have found that a big part of it is actually the language understanding. Image models once would have needed a reference photo in its training data of a black dog in a forest to understand that request. But the improved language model part made it so the concepts of black, dog, and forest (as well as ones like “in” and “under”) are understood independently and completely. It “knows” what the color black is and what a dog is, so even if it has no black dog in its training data, the two concepts can be connected on the map’s “latent space.” This means the model doesn’t have to improvise and guess at what an image ought to look like, something that caused a lot of the weirdness we remember from generated imagery. There are different ways of actually producing the image, and researchers are now also looking at making video in the same way, by adding actions into the same map as language and imagery. Now you can have “white kitten jumping in a field” and “black dog digging in a forest,” but the concepts are largely the same. It bears repeating, though, that like before, the AI is just completing, converting, and combining patterns in its giant statistics maps! While the image-creation capabilities of AI are very impressive, they don’t indicate what we would call actual intelligence. The concept of “artificial general intelligence,” also called “strong AI,” varies depending on who you talk to, but generally it refers to software that is capable of exceeding humanity on any task, including improving itself. This, the theory goes, could produce a runaway AI that could, if not properly aligned or limited, cause great harm — or if embraced, elevate humanity to a new level. But AGI is just a concept, the way interstellar travel is a concept. We can get to the moon, but that doesn’t mean we have any idea how to get to the closest neighboring star. So we don’t worry too much about what life would be like out there — outside science fiction, anyway. It’s the same for AGI. Although we’ve created highly convincing and capable machine learning models for some very specific and easily reached tasks, that doesn’t mean we are anywhere near creating AGI. Many experts think it may not even be possible, or if it is, it might require methods or resources beyond anything we have access to. Of course, it shouldn’t stop anyone who cares to think about the concept from doing so. But it is kind of like someone knapping the first obsidian speartip and then trying to imagine warfare 10,000 years later. Would they predict nuclear warheads, drone strikes, and space lasers? No, and we likely cannot predict the nature or time horizon of AGI, if indeed it is possible. Some feel the imaginary existential threat of AI is compelling enough to ignore many current problems, like the actual damage caused by poorly implemented AI tools. This debate is nowhere near settled, especially as the pace of AI innovation accelerates. But is it accelerating towards superintelligence, or a brick wall? Right now there’s no way to tell. We’re launching an AI newsletter! Sign up here to start receiving it in your inboxes on June 5. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                     Featured Article           Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Orby is building AI agents for the enterprise': ' Comment AI “agents” are generative AI models that can perform actions autonomously, like copying info from an email and pasting it into a spreadsheet, and have been hailed as productivity superchargers. That might be a bit premature, given models’ tendency to make mistakes. But at least a few founders (and analysts and investors) seem convinced that agents are the next frontier in generative AI. Bella Liu and William Lu are two such founders. Their company, Orby AI, is building a generative AI platform that attempts to automate a range of different business workflows, including workflows that involve data entry, documents processing and forms validation. Lots of startups offer tools to automate repetitive, monotonous back-office business processes (see Parabola, Tines, Sam Altman-backed Induced AI and Tektonic AI, to name a few). Incumbents, too, like Automation Anywhere and UiPath, have moved to embrace AI to try to maintain pace with the generative AI competition. But Liu and Lu claim that Orby’s tech stands out for its ability to learn and act on workflows in real time and to understand the patterns and relationships within an enterprise’s unstructured data. “Orby’s platform observes how workers do their work in order to automatically create automations for complex tasks that require some level of reasoning and understanding,” Liu, Orby’s CEO, explained. “An AI agent installed on a worker’s computer effectively watches, learns and generates automations, adapting the model as it learns more.” With Orby, which launched out of stealth in 2023, Liu and Lu say that they sought to create AI that could understand some of the low-level decisions being made by workers and abstract those decisions away, freeing up workers to focus on headier things. Liu previously led AI and automation efforts at IBM, including product planning and AI-related mergers and acquisitions, and was UiPath’s director of AI product management. Lu is a former Nvidia systems engineer who joined Google Cloud as an engineering lead, helping to design generative AI document and database extraction tech. Orby’s purported secret sauce is a cloud-based generative AI model that’s fine-tuned to complete customer tasks, such as validating expense reports. The model relies partly on symbolic AI, a form of AI that leverages rules, such as mathematical theorems, to infer solutions to problems. Symbolic AI alone can be inflexible and slow, especially when dealing with large and complicated datasets. It needs clearly defined knowledge and context to perform well. But recent research has shown that it can be scalable when paired with traditional AI model architectures. “For the last two years, we’ve been engineering this AI model, and have performed successful trials,” Liu said. “There are few pure-play generative AI companies attacking the enterprise head-on with something end-to-end. We are one.” Liu says that Orby’s model can intelligently adapt to changes in workflows, like when an app’s UI gets an update, by analyzing API interactions and a worker’s browser usage. Having software monitor an employee’s every move sound like a privacy disaster waiting to happen. But Liu claims that Orby doesn’t store most customer data; it only uses certain telemetry data to improve its model, encrypting the data both in transit and at rest. “Humans are kept completely in the feedback loop,” she added. Orby, which recently raised $30 million in a Series A funding round co-led by New Enterprise Associates, WndrCo and Wing (sources say at a post-money valuation of $120 million), is competing in a challenging sector. Forthcoming agentic AI from generative AI powerhouses such as OpenAI and Anthropic have dampened the prospects of incumbents and smaller players alike. Adept, a startup building AI agents technology focused on enterprise applications, is reportedly on the cusp of an acqui-hire deal with Microsoft before it manages to ship a single product. Amazon and Google have released AI agent tooling to little fanfare. Elsewhere, UiPath — despite its ramping up of generative AI initiatives in the past year — saw sales plummet in its most recent fiscal quarter. Liu says that Orby can come out ahead by taking a systematic go-to-market approach. The company is already generating revenue from around a dozen customers, she says, and plans to put its $35 million war chest toward expanding its Mountain View-based, roughly 30-person team. “The funds are being used to scale our go-to-market, customer support, product and technical orgs,” she said. “The enterprise market has an insatiable appetite for generative AI solutions that demonstrably improve business performance; they are just trying to figure out where to best apply the technology in the near term before they scale it across their business.” Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                       Featured Article         Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'UK opens office in San Francisco to tackle AI risk': ' Comment Ahead of the AI safety summit kicking off in Seoul, South Korea later this week, its co-host, the United Kingdom, is expanding its own efforts in the field. The AI Safety Institute, a U.K. body set up in November 2023 with the ambitious goal of assessing and addressing risks in AI platforms, has said it will open a second location in San Francisco.  The idea is to get closer to the epicenter of AI development. The Bay Area is the home of companies like OpenAI, Anthropic, Google and Meta that are building foundational AI technology. Foundational models are the building blocks of generative AI services and other applications, and it’s interesting that although the U.K. has signed an MOU with the U.S. to collaborate on AI safety initiatives, the U.K. is still choosing to set up in the U.S. to tackle the issue. “By having people on the ground in San Francisco, it will give them access to the headquarters of many of these AI companies,” Michelle Donelan, the U.K. secretary of state for science, innovation and technology, said in an interview with TechCrunch. “A number of them have bases here in the United Kingdom, but we think that would be very useful to have a base there as well, and access to an additional pool of talent, and be able to work even more collaboratively and hand-in-glove with the United States.” Part of the reason is that being closer to that epicenter is useful not just for understanding what is being built, it also gives the U.K. more visibility with these firms. That’s important, since AI and technology is seen by the U.K. as a huge opportunity for economic growth and investment.  And given the latest drama at OpenAI around its Superalignment team, it feels like an especially timely moment to establish a presence there. The AI Safety Institute, launched in November 2023, is a relatively modest affair today. The organization has just 32 employees, a veritable David to the Goliath of AI tech, when you consider the billions of dollars of investment riding on the companies building AI models and their own economic motivations for getting their technologies into the hands of paying users.  One of the AI Safety Institute’s most notable developments was the release of Inspect, its first set of tools for testing the safety of foundational AI models, earlier this month.  Donelan today referred to that release as a “phase one” effort. Not only has it proven challenging to benchmark models, but for now, engagement is very much an opt-in and inconsistent arrangement. As one senior source at a U.K. regulator pointed out, companies are under no legal obligation to have their models vetted at this point; and not every company is willing to have their models vetted before release. That could mean, in cases where risk might be identified, the horse may have already bolted.  Donelan said the AI Safety Institute was still working on strategies to engage with AI companies to evaluate them. “Our evaluation process is an emerging science in itself,” she said. “So with every evaluation, we will develop the process and finesse it even more.” Donelan said that one goal of the conference in Seoul is to present Inspect to regulators, aiming to get them to adopt it, too.  “Now we have an evaluation system. Phase two needs to also be about making AI safe across the whole of society,” she said.  Longer term, Donelan believes the U.K. will be building more AI legislation, although, repeating what Prime Minister Rishi Sunak has said on the topic, it will resist doing so until it better understands the scope of AI risks.  “We do not believe in legislating before we properly have a grip and full understanding,” she said, noting that the institute’s recent international AI safety report, focused primarily on trying to get a comprehensive picture of research to date, “highlighted that there are big gaps missing and that we need to incentivize and encourage more research globally.” “Also, legislation takes about a year in the United Kingdom. If we had just started legislation when we started instead of [organizing] the AI Safety Summit [held in November last year], we’d still be legislating now, and we wouldn’t actually have anything to show for that,” Donelan said. “Since day one of the Institute, we have been clear on the importance of taking an international approach to AI safety, share research, and work collaboratively with other countries to test models and anticipate risks of frontier AI,” said Ian Hogarth, chair of the AI Safety Institute, in a statement. “Today marks a pivotal moment that allows us to further advance this agenda, and we are proud to be scaling our operations in an area bursting with tech talent, adding to the incredible expertise that our staff in London has brought since the very beginning.” Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'The top AI features Apple announced at WWDC 2024': ' Comment Monday was the kickoff of WWDC 2024, the annual event where Apple announces some of the biggest features headed to its devices, apps and software. And this year’s WWDC is a doozy. Thanks to Apple’s newfound — and heavy — investment in generative AI tech, the company had loads to showcase on the AI front, from an upgraded Siri to AI-generated emoji. Apple announced a deal with OpenAI to bring ChatGPT, OpenAI’s AI-powered chatbot experience, to a range of its devices. It introduced new photo-editing tools to remove objects and people from photos. And it rolled out an AI capability to proofread, rewrite and summarize text across content, including notes to emails. Here’s a roundup of a few of the more noteworthy Apple AI announcements from WWDC 2024. Siri got a makeover courtesy of Apple’s overarching generative AI push this year, called Apple Intelligence. Thanks to Apple Intelligence, Siri, which has a revamped look, including a new icon and glowing indicator light around the edges of a device’s screen, can now handle stumbles in speech and better understand context. You can now also type to Siri, and it can answer questions, including questions about how to use your iPhone, iPad or Mac. Soon, Siri will become even more capable with onscreen awareness and the ability to take action in and across apps — so you can ask Siri to, for example, “make this photo pop” and then “add this photo” to another app. During the WWDC keynote on Monday, Apple gave the example of Siri finding a photo of your license, extracting your ID number and entering it into a web form for you. To take advantage of the new Siri, you’ll need an Apple device that supports Apple Intelligence — specifically the iPhone 15 Pro and devices with M1 or newer chips. Apple’s bringing ChatGPT to Siri and other first-party apps and capabilities across its operating systems. Siri users will soon be able to route questions to ChatGPT for “expertise” where it might be helpful, Apple says. You can include photos with the questions you ask ChatGPT via Siri, or ask questions related to your docs or PDFs. Apple’s also integrated ChatGPT into OS-wide tools such as Writing Tools (powered by Apple Intelligence), which allows you to create content with ChatGPT — including images — or ask an initial idea and send it to ChatGPT to get a revision or variation back. ChatGPT integrations will arrive on iOS 18, iPadOS 18 and macOS Sequoia later this year, Apple says, and will be free without the need to create a ChatGPT or OpenAI account. Initially, they’ll be powered by GPT-4o, OpenAI’s recently introduced flagship generative AI model. Genmoji, coming soon to iOS 18 on devices that support Apple Intelligence, lets you create AI emoji-like images of anyone in your photo library — or just custom emoji. Genmoji can be used as a sticker for reacting to messages with a Tapback or inline with your messages, Apple says. A separate new image-generation capability allows iPhone users to create AI images of people they’re messaging with. Apple Intelligence will have an understanding of who you’re chatting with, Apple says — so if you want to personalize the chat with a custom AI image, you can do so on the fly. There’s also Image Playground, a new image-generating feature that works across apps like Notes, Freeform, Keynote and Pages. Available as a standalone app and API for developers, Image Playground allows users to create images using concepts such as themes, costumes, accessories, places and more. You select the themes you want to include and, minutes later, Image Playground creates a preview of your image. Apple’s new Clean Up tool, built into the upgraded Photos app, removes unwanted people and objects from pics. Clean Up can be used on any picture in Photos by circling or highlighting the thing — or person — to be removed. Relying on AI, Clean Up removes the selected element and replaces it with contextually-aware pixels to try to make it seem like the thing (or person) was never there to begin with. On the subject of Photos, it’s now better organized thanks to AI. Coming in iOS 18, Photos will show collections of photos automatically organized by topics like time, people, favorite memories, trips and more. And you’ll be able to use more specific terms to search across photos. Coming soon to iPhone 15 Pro and newer models, iOS will optionally record and transcribe your phone calls. The feature — which must be enabled manually, and which informs the party on the other end of the line that the call is being recorded so as to not run afoul of privacy laws — transcribes what’s said during the call and then provides a summary of the key points discussed in iOS’ Notes app. Apple noted (no pun intended) during the keynote on Monday that you’ll also be able to record and transcribe audio from within the Notes app. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                      Featured Article          Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'EasyTranslate thinks augmenting LLMs with humans will give it an edge over pure AI translation services': ' Comment You might think new generative AI startups like Eleven Labs are the hottest game in town for translation services. But voice translation was long ago preceded by another market, targeted some time ago by startups: content translation. Any company with an international presence needs to have their content translated around the world, so this remains a big market. This was evidenced by the $106 million raised to date by the likes of Unbabel in Portugal (which last raised $60 million).  EasyTranslate, which specializes in content translation, has been around since 2010, using machine learning models to identify which freelance translators were best suited to translate specific types of content. But now it’s headed in a different direction with a new, generative AI-driven platform that it calls “HumanAI.” “We have pivoted the whole business model from a human service-based business model towards being an AI technology provider, driving down the cost and speeding up the process,” the company’s founder, Frederik R. Pedersen, told TechCrunch.  Most translation services offer machine-translated content, with a small portion edited by humans. However, translators often must assess the entire machine-generated translation to understand the context and make sense of the content. EasyTranslate’s HumanAI platform flips this on its head, absorbing content, blending it with large language models (LLMs) and employing short-term memory in the LLM to translate content more accurately. What’s more, it will only involve humans where it needs to, thus reducing translation times and costs. To do this, HumanAI uses a mix of LLMs, including the one offered by OpenAI, as well as its own recommendation systems. The platform runs off its own algorithms and customer data to provide customized content translation. The secret to the pivot, Pedersen said, is using LLMs to generate short-term memory so the platform can read a translation in generic English and turn it into specific English. It “vectors” content into a database, enabling it to do a semantic search and find similarities between content, which is then used to create a short-term memory with an LLM (this is also referred to as retrieval augmented generation). This means the platform can use any number of LLMs to translate between, for example, the English used in marketing copy or English employed in finance reports, and preserve the meaning in the text all the while.  “We can combine the more traditional, neural machine translation engines with customer-specific data to create a foundation for the localization and translation process. So, moving from generic language towards customer-specific language, for instance,” he said. Why is that important? Pedersen explained: “You might get a grammatically perfect machine-based translation, but it still may not sound right. So we identify which part of the content has a low confidence score and then use humans to correct it. The combination massively increases our productivity.” Pederson claimed HumanAI can drive down translation costs by 90% and ends up pricing its services at €0.01 per translated word. Its customers include global businesses such as Wix and Monday.com.  And pricing is an especially crucial puzzle to solve in this space because companies have a great deal of content that needs translating. “If you look at Adobe, they have a full team just looking at how the terminologies align across markets. And if we look at global brands, there’s a significant amount of effort put into making sure that you are perceived in the right way locally,” Pedersen said. The question is, though, what will help EasyTranslate compete against pure-play AI-based solutions, which are likely to get better with time? “Our goal is not to become a pure AI [service]. I think our goal is to create the added value of having humans combined with AI, and provide this service to customers. AI still needs human feedback to be improved,” he said. “It’s one thing to say you would like to implement all content creation, all translation, and another to make sure that you can actually control the model. You have to have some humans to control the models, because humans are not machines and language changes constantly.” EasyTranslate has raised a total of €3 million to date and is backed by private equity, debt financing, some angel investors in Copenhagen and the Danish Innovation Fund.  Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Apple signs the White House’s commitment to AI safety': ' Comment Apple signed the White House’s voluntary commitment to developing safe, secure and trustworthy AI, according to a press release on Friday. The company will soon launch its generative AI offering, Apple Intelligence, into its core products, putting generative AI in front of Apple’s 2 billion users. Apple joins 15 other technology companies — including Amazon, Anthropic, Google, Inflection, Meta, Microsoft and OpenAI — that committed to the White House’s ground rules for developing generative AI in July 2023. At the time, Apple had not revealed how deeply it planned to ingrain AI into iOS. But we heard Apple loud and clear at WWDC in June: It’s going all in on generative AI, starting with a partnership that embeds ChatGPT in the iPhone. As a frequent target of federal regulators, Apple wants to signal early that it’s willing to play by the White House’s rules on AI — a possible attempt to curry favor before any future regulatory battles on AI break out. But how much teeth do Apple’s voluntary commitments to the White House have? Not much, but it’s a start. The White House calls this the “first step” toward Apple and 15 other AI companies developing AI that is safe, secure and trustworthy. The second step was President Biden’s AI executive order in October, and there are several bills currently moving through federal and state legislatures to better regulate AI models. Under the commitment, AI companies promise to red-team (acting as an adversarial hacker to stress test an organization’s safety measures) AI models before a public release and share that information with the public. The White House’s voluntary commitment also asks AI companies to treat unreleased AI model weights confidentially. Apple and other companies agree to work on AI model weights in secure environments, limiting access to model weights to as few employees as possible. Lastly, the AI companies agree to develop content labeling systems, such as watermarking, to help users distinguish what is and isn’t AI generated. Separately, the Department of Commerce says it will soon release a report on the potential benefits, risks and implications of open-source foundation models. Open-source AI is increasingly becoming a politically charged regulatory battlefield. Some camps want to limit how accessible model weights to powerful AI models should be in the name of safety. However, doing so could significantly limit the AI startup and research ecosystem. The White House’s stance here could have a significant impact on the greater AI industry. The White House also noted that federal agencies have made significant progress on tasks set out by the October executive order. Federal agencies have made more than 200 AI-related hires to date, awarded more than 80 research teams’ access to computational resources, and released several frameworks for developing AI (the government loves frameworks). Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                 Featured Article           Featured Article     Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Level AI applies algorithms to contact center pain points': ' Comment Ashish Nagar, an engineer by trade, was working at Amazon’s Alexa org on the conversational AI team when he realized that AI had the potential to greatly bolster productivity in contact centers. “Frontline workers, like customer service workers, are the biggest human capital in the world,” Nagar told TechCrunch. “So, my idea was to use ambient computing — AI that you can just talk to and it listens in the background — to augment human work.” In 2019, Nagar founded Level AI, which offers a suite of AI-powered tools to automate various customer service tasks. The platform can score contact center agents on metrics like total conversations and “dead air,” for example, generating insights for both managers and the agents themselves. “Level AI’s software enables brands to get insights on the pulse of the customer, quality of the service being delivered and action plans to improve service performance,” Nagar said. So what else can Level AI do? Depending on how the platform’s configured, it can show hints to agents throughout a conversation with a customer, like a reminder to authenticate the customer’s identity. Level AI can also attempt to gauge a customer’s sentiment and respond appropriately, for example highlighting for an agent that a customer is upset about a late delivery. And it hosts coaching tools designed to help managers walk agents through steps to improve their performance in areas like response time. “Key challenges in the AI-powered customer service industry include data privacy and security concerns, the need for seamless integration with existing systems, ensuring AI accuracy and reliability and addressing potential job displacement fears,” Nagar said. “Additionally, there’s an ongoing challenge to keep pace with rapidly evolving AI technologies while maintaining ethical standards and regulatory compliance. Level AI is built from the ground up to address these concerns.” Nagar is naturally optimistic about how Level AI’s platform is being and will be deployed. But there’s a very real dark side to call center monitoring software. An op-ed in The Guardian reveals how call centers often become “electronic panopticons” where staff are constantly watched, and where minor errors are used to discipline and fire workers on the spot. That, along with low pay and the psychological toll of dealing with emotional customers, could be one of the reasons that turnover rates in the contact center industry are exceptionally high, averaging between 30% to 45% annually. And then there’s the privacy implications of tools like Level AI. Do customers know that what they say is being analyzed by sentiment-classifying algorithms, and can employees expect their personal data to be deleted at some point? Nagar says it’s up to the organizations using Level AI to define their own data retention policies. “We provide flexibility for customers to control and manage their data,” he clarified. And customers seem to like this flexibility. Companies including Affirm, Penske and Carta are signed up for Level AI, according to Nagar, which makes money through annual contracts calculated in part by the number of agents using Level AI’s platform. Nagar wouldn’t disclose revenue figures, but he said that he thinks the company could eclipse $50 million in annual recurring revenue in the next two or so years. Looking at the larger market for contact center software, that’s not completely unreasonable. According to analytics firm Mordor Intelligence, the sector was worth $61.07 billion in 2024 and could climb to $145.20 billion by 2029, driven in part by contact center operators wanting to cut costs. It seems at least some VCs agree with Nagar’s lofty projection, too. Level AI closed a $39.4 million Series C funding round this month led by Adams Street Partners with participation from Cross Creek, Brightloop and two existing investors, Battery Ventures and Eniac Ventures, which brought the startup’s total raised to $73.1 million. Nagar said that the fresh capital will be put toward expanding Mountain View-based Level AI’s platform to new customer segments. “We’ve already shown very strong traction with enterprise customers, and this funding will enable us to scale our solution to even more customers,” Nagar said, adding that Level AI plans to expand its 135-person workforce by at least a dozen people in the next six months. “We continue to innovate in the space with four product offerings already, and we will continue to heavily invest in our people and technology to continue this trend.” Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.     Featured Article                           Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Ilya Sutskever, OpenAI’s former chief scientist, launches new AI company': ' Comment Ilya Sutskever, one of OpenAI’s co-founders, has launched a new company, Safe Superintelligence Inc. (SSI), just one month after formally leaving OpenAI. Sutskever, who was OpenAI’s longtime chief scientist, founded SSI with former Y Combinator partner Daniel Gross and ex-OpenAI engineer Daniel Levy. At OpenAI, Sutskever was integral to the company’s efforts to improve AI safety with the rise of “superintelligent” AI systems, an area he worked on alongside Jan Leike, who co-led OpenAI’s Superalignment team. Yet both Sutskever and then Leike left the company in May after a dramatic falling out with leadership at OpenAI over how to approach AI safety. Leike now heads a team at rival AI shop Anthropic. Sutskever has been shining a light on the thornier aspects of AI safety for a long time now. In a blog post published in 2023, Sutskever, writing with Leike, predicted that AI with intelligence superior to humans could arrive within the decade — and that when it does, it won’t necessarily be benevolent, necessitating research into ways to control and restrict it. He’s clearly as committed as ever to the cause today. Wednesday afternoon, a tweet announcing the formation of Sutskever’s new company states that: “SSI is our mission, our name, and our entire product roadmap, because it is our sole focus. Our team, investors, and business model are all aligned to achieve SSI. We approach safety and capabilities in tandem, as technical problems to be solved through revolutionary engineering and scientific breakthroughs.” “We plan to advance capabilities as fast as possible while making sure our safety always remains ahead. This way, we can scale in peace. Our singular focus means no distraction by management overhead or product cycles, and our business model means safety, security, and progress are all insulated from short-term commercial pressures.” Sutskever spoke with Bloomberg about the new company in greater detail, though he declined to discuss its funding situation or valuation. More apparent is that unlike OpenAI — which originally launched as a nonprofit organization in 2015, then restructured itself when the vast sums of money needed for its computing power became more obvious — SSI is being designed from the ground up as a for-profit entity. Judging by interest in AI and the team’s credentials specifically, it may be drowning in capital very soon, too. “Out of all the problems we face,” Gross tells Bloomberg, “raising capital is not going to be one of them.” SSI has offices in Palo Alto and Tel Aviv, where it is currently recruiting technical talent. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                       Featured Article         Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Grammy CEO says music industry also has AI concerns': ' Comment Harvey Mason Jr., CEO of the Recording Academy, caused a stir a few months ago.  He announced that the organization’s prestigious Grammy Awards would finally accept music made with artificial intelligence. At first, people were confused, and then Mason came out to clarify that he meant only humans can submit to the awards, but that AI can be used in the creative process.  “It’s a bit of a fine line, but that’s going to evolve,” he told TechCrunch about how the Academy is assessing the use of artificial intelligence in music. “My hope is that we can continue to celebrate human creativity at the highest level.”  The rise of AI has consumed the arts, just as it has Silicon Valley. Everyone is pondering: Will AI replace me? And within music — what happens to copyright? Royalties? To the hard work I’ve put into my craft? Mason said there are indeed concerns sweeping the industry. Some people are scared and nervous, while others are excited and optimistic. Some artists are sending cease-and-desist letters to get unauthorized deepfakes of themselves taken down, while others are embracing their AI versions — so long as they get paid.  “I wholeheartedly believe that AI in music shouldn’t even exist,” musician Devante, the Artist told TechCrunch. “AI should really only be used for simple daily tasks. As an artist, the ‘AI is taking over the world’ take is very real these days. Music is my world and now it’s all too easy for someone to masquerade as something it’s taken my whole life to be.”  “I think a lot of musicians, particularly the ones who haven’t ‘made it,’ are taking a glass-half-empty perspective on AI,” a musician who also works for a Big Tech company told TechCrunch. He asked to remain anonymous because he did not have permission from his employer to speak on the matter. “Just as the industrial revolution did not lead to widespread unemployment and in fact quite the opposite, more creatives, especially musicians, should flip their mindset and lean in.”  AI is already being used in music, mostly in the process of mastering and equalizing sounds, Mason said. The biggest concerns right now in the industry are making sure people get the right approvals to use an artist’s work, making sure humans are credited separately from AI, and making sure people are getting paid fairly, whether that’s the copyright AI is trained on or the likeness of an artist. There’s also the issue of ensuring these protections across the industry.  Mason co-launched the Human Artistry Campaign to address some of these issues and advocate for more guardrails around the use of AI.  He was involved with the ELVIS Act, passed in Tennessee, which gives artists more protection over the unauthorized use of their voices. He’s also supporting the No AI Fraud Act and the No FAKES Act, which will protect creators’ likenesses from AI fakes.  It’s a pressing matter that is moving faster than the law. This month, Donald Trump found himself in tricky legal water after using unauthorized AI images of Taylor Swift to help promote his presidential campaign. At the time, TechCrunch reported that the ELVIS Act is so new that there is no precedent on how it could be used to protect an artist like Swift in this situation. (Mason declined to comment on the matter then.)  The push for more legislation within the music industry is quite interesting given the fact that the topic has caused much debate in Silicon Valley. Some AI purveyors in the U.S. favor a more laissez-faire attitude toward the technology in its early days and believe too many guardrails could hinder innovation. Others are looking at it from a societal standpoint, wanting protections against the impact that unchecked AI could have on people. Governments across the U.S. — and even on a national stage — are battling this out now.  Devante, the Artist feels there is a disconnect between what is being done to regulate AI versus what should be done. He wants to see the development of AI slowed down or see innovation that can help protect music, such as a type of filter that can differentiate AI vocals from human ones. “As it comes to our industry and the creative community, there’s still a concern,” Mason said. “There’s uncertainty because there just doesn’t seem to be protections in place.”  In 2020, when Mason first became president of the Recording Academy, AI was hardly a topic of discussion. Then, around 2023, everything started to change. A deepfake song featuring trained, unauthorized AI vocals on Drake and the Weeknd went viral. Fans loved it, and the person who created the song spoke of possibly entering the song into the Grammys. The Academy had to act fast, dealing with something it had never dealt with before. “That was the point at which we started having to pay close attention to it,” Mason said.  The song was deemed ineligible for the Grammys and was taken down, but its legacy lived on. The highest profile AI situation since then ironically also involved Drake. During the Drake-Kendrick Lamar feud, Drake used unauthorized AI vocals of the late hip-hop icon Tupac in an attempted diss track against Lamar and was immediately threatened with a lawsuit by Tupac’s estate for using his likeness without permission.  Meanwhile, producer Metro Boomin, who also has qualms with Drake, created an AI song called “BBL Drizzy,” which fans raved about, even after learning it was AI. Mason said consumers aren’t always going to know when something is AI — nor will they always go through the credits to find out. Mason said that many consumers don’t seem to care much about whether AI is used in music, another reason why protecting creators is so important.  “I don’t think people care what they consume,” Devante, the Artist agreed. “It’s almost like a ‘not me, not my problem situation.’”  At the same time, Mason believes that humans will just evolve to live with AI, just like they’ve adapted to nearly every other new form of technology. Years ago, artists had to learn how to use synthesizers or how to sample music. The latter especially posed a problem, as some artists would just sample another person’s music without permission. Eventually, the industry went back and figured out a standard way to allocate credit and royalties. “We’ll make great music with the new technology,” Mason said about AI. “But I just want to make sure it’s done in a way that’s fair to the human creators.”  This story was updated to clarify the AI song of Drake and the Weeknd submitted to the Grammys. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                       Featured Article         Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Women in AI: Miriam Vogel stresses the need for responsible AI': ' Comment To give AI-focused women academics and others their well-deserved — and overdue — time in the spotlight, TechCrunch has been publishing a series of interviews focused on remarkable women who’ve contributed to the AI revolution. We’re publishing these pieces throughout the year as the AI boom continues, highlighting key work that often goes unrecognized. Read more profiles here. Miriam Vogel is the CEO of EqualAI, a nonprofit created to reduce unconscious bias in AI and promote responsible AI governance. She also serves as chair to the recently launched National AI Advisory Committee, mandated by Congress to advise President Joe Biden and the White House on AI policy, and teaches technology law and policy at Georgetown University Law Center. Vogel previously served as associate deputy attorney general at the Justice Department, advising the attorney general and deputy attorney general on a broad range of legal, policy and operational issues. As a board member at the Responsible AI Institute and senior advisor to the Center for Democracy and Technology, Vogel’s advised White House leadership on initiatives ranging from women, economic, regulatory and food safety policy to matters of criminal justice. Briefly, how did you get your start in AI? What attracted you to the field? I started my career working in government, initially as a Senate intern, the summer before 11th grade. I got the policy bug and spent the next several summers working on the Hill and then the White House. My focus at that point was on civil rights, which is not the conventional path to artificial intelligence, but looking back, it makes perfect sense. After law school, my career progressed from an entertainment attorney specializing in intellectual property to engaging civil rights and social impact work in the executive branch. I had the privilege of leading the equal pay task force while I served at the White House, and, while serving as associate deputy attorney general under former deputy attorney general Sally Yates, I led the creation and development of implicit bias training for federal law enforcement. I was asked to lead EqualAI based on my experience as a lawyer in tech and my background in policy addressing bias and systematic harms. I was attracted to this organization because I realized AI presented the next civil rights frontier. Without vigilance, decades of progress could be undone in lines of code. I have always been excited about the possibilities created by innovation, and I still believe AI can present amazing new opportunities for more populations to thrive — but only if we are careful at this critical juncture to ensure that more people are able to meaningfully participate in its creation and development. How do you navigate the challenges of the male-dominated tech industry, and, by extension, the male-dominated AI industry? I fundamentally believe that we all have a role to play in ensuring that our AI is as effective, efficient and beneficial as possible. That means making sure we do more to support women’s voices in its development (who, by the way, account for more than 85% of purchases in the U.S., and so ensuring their interests and safety is incorporated is a smart business move), as well as the voices of other underrepresented populations of various ages, regions, ethnicities and nationalities who are not sufficiently participating. As we work toward gender parity, we must ensure more voices and perspectives are considered in order to develop AI that works for all consumers — not just AI that works for the developers. What advice would you give to women seeking to enter the AI field? First, it is never too late to start. Never. I encourage all grandparents to try using OpenAI’s ChatGPT, Microsoft’s Copilot or Google’s Gemini. We are all going to need to become AI-literate in order to thrive in what is to become an AI-powered economy. And that is exciting! We all have a role to play. Whether you are starting a career in AI or using AI to support your work, women should be trying out AI tools, seeing what these tools can and cannot do, seeing whether they work for them and generally become AI-savvy. Second, responsible AI development requires more than just ethical computer scientists. Many people think that the AI field requires a computer science or some other STEM degree when, in reality, AI needs perspectives and expertise from women and men from all backgrounds. Jump in! Your voice and perspective is needed. Your engagement is crucial. What are some of the most pressing issues facing AI as it evolves? First, we need greater AI literacy. We are “AI net-positive” at EqualAI, meaning we think AI is going to provide unprecedented opportunities for our economy and improve our daily lives — but only if these opportunities are equally available and beneficial for a greater cross-section of our population. We need our current workforce, next generation, our grandparents — all of us — to be equipped with the knowledge and skills to benefit from AI. Second, we must develop standardized measures and metrics to evaluate AI systems. Standardized evaluations will be crucial to building trust in our AI systems and allowing consumers, regulators and downstream users to understand the limits of the AI systems they are engaging with and determine whether that system is worthy of our trust. Understanding who a system is built to serve and the envisioned use cases will help us answer the key question: For whom could this fail? What are some issues AI users should be aware of? Artificial intelligence is just that: artificial. It is built by humans to “mimic” human cognition and empower humans in their pursuits. We must maintain the proper amount of skepticism and engage in due diligence when using this technology to ensure that we are placing our faith in systems that deserve our trust. AI can augment — but not replace — humanity. We must remain clear-eyed on the fact that AI consists of two main ingredients: algorithms (created by humans) and data (reflecting human conversations and interactions). As a result, AI reflects and adapts our human flaws. Bias and harms can embed throughout the AI lifecycle, whether through the algorithms written by humans or through the data that is a snapshot of human lives. However, every human touchpoint is an opportunity to identify and mitigate the potential harm. Because one can only imagine as broadly as their own experience allows and AI programs are limited by the constructs under which they are built, the more people with varied perspectives and experiences on a team, the more likely they are to catch biases and other safety concerns embedded in their AI. What is the best way to responsibly build AI? Building AI that is worthy of our trust is all of our responsibility. We can’t expect someone else to do it for us. We must start by asking three basic questions: (1) For whom is this AI system built (2), what were the envisioned use cases and (3) for whom can this fail? Even with these questions in mind, there will inevitably be pitfalls. In order to mitigate against these risks, designers, developers and deployers must follow best practices. At EqualAI, we promote good “AI hygiene,” which involves planning your framework and ensuring accountability, standardizing testing, documentation and routine auditing. We also recently published a guide to designing and operationalizing a responsible AI governance framework, which delineates the values, principles and framework for implementing AI responsibly at an organization. The paper serves as a resource for organizations of any size, sector or maturity in the midst of adopting, developing, using and implementing AI systems with an internal and public commitment to do so responsibly. How can investors better push for responsible AI? Investors have an outsized role in ensuring our AI is safe, effective and responsible. Investors can ensure the companies seeking funding are aware of and thinking about mitigating potential harms and liabilities in their AI systems. Even asking the question, “How have you instituted AI governance practices?” is a meaningful first step in ensuring better outcomes. This effort is not just good for the public good; it is also in the best interest of investors who will want to ensure the companies they are invested in and affiliated with are not associated with bad headlines or encumbered by litigation. Trust is one of the few non-negotiables for a company’s success, and a commitment to responsible AI governance is the best way to build and sustain public trust. Robust and trustworthy AI makes good business sense. We’re launching an AI newsletter! Sign up here to start receiving it in your inboxes on June 5. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Why code-testing startup Nova AI uses open source LLMs more than OpenAI': ' Comment It is a universal truth of human nature that the developers who build the code should not be the ones to test it. First of all, most of them pretty much detest that task. Second, like any good auditing protocol, those who do the work should not be the ones who verify it. Not surprisingly, then, code testing in all its forms — usability, language- or task-specific tests, end-to-end testing — has been a focus of a growing cadre of generative AI startups. Every week, TechCrunch covers another one like Antithesis (raised $47 million), CodiumAI (raised $11 million) and QA Wolf (raised $20 million). And new ones are emerging all the time, like new Y Combinator graduate Momentic. Another is year-old startup Nova AI, an Unusual Academy accelerator grad that’s raised a $1 million pre-seed round. It is attempting to best its competitors with its end-to-end testing tools by breaking many of the Silicon Valley rules of how startups should operate, founder/CEO Zach Smith tells TechCrunch. Whereas the standard Y Combinator approach is to start small, Nova AI is aiming at mid-size to large enterprises with complex code-bases and a burning need now. Smith declined to name any customers using or testing its product except to describe them as mostly late-stage (Series C or beyond) venture-backed startups in e-commerce, fintech or consumer products, and “heavy user experiences. Downtime for these features is costly.” Nova AI’s tech sifts through its customers’ code to build tests automatically using GenAI. It is particularly geared toward continuous integration and continuous delivery/deployment (CI/CD) environments where engineers are constantly shipping bits and pieces into their production code. The idea for Nova AI came from the experiences Smith and his co-founder Jeffrey Shih had when they were engineers working for big tech companies. Smith is a former Googler who worked on cloud-related teams that helped customers use a lot of automation technology. Shih previously worked at Meta (also at Unity and Microsoft before that) with a rare AI specialty involving synthetic data. They’ve since added a third co-founder, AI data scientist Henry Li. Another rule Nova AI is not following: While boatloads of AI startups are building on top of OpenAI’s industry-leading GPT, Nova AI is using OpenAI’s Chat GPT-4 as little as possible. No customer data is being fed to OpenAI. While OpenAI promises that the data of those on a paid business plan is not being used to train its models, enterprises still do not trust OpenAI, Smith tells us. “When we’re talking to large enterprises, they’re like, ‘We don’t want our data going into OpenAI,” Smith said. The engineering teams of large companies are not the only ones that feel this way. OpenAI is fending off a number of lawsuits from those who don’t want it to use their work for model training, or believe their work wound up, unauthorized and unpaid for, in its outputs. Nova AI is instead heavily relying on open source models like Llama developed by Meta and StarCoder (from the BigCoder community, which was developed by ServiceNow and Hugging Face), as well as building its own models. They aren’t yet using Google’s Gemma with customers, but have tested it and “seen good results,” Smith says. For instance, he explains that OpenAI offers models for vector embeddings. Vector embeddings translate chunks of text into numbers so the LLM can perform various operations, such as clustering them with other chunks of similar text. Nova AI doesn’t use OpenAI’s embeddings and instead uses open source for this on the customer’s source code. It uses OpenAI tools only to help it generate some code and to do some labeling tasks, and is going through lengths not to send any customer data into OpenAI. “In this case, instead of using OpenAI’s embedding models, we deploy our own open source embedding models so that when we need to run through every file, we aren’t just sending it to OpenAI,” Smith explained. While not sending customer data to OpenAI appeases nervous enterprises, open source AI models are also cheaper and more than sufficient for doing targeted specific tasks, Smith has found. In this case, they work well for writing tests. “The open LLM industry is really proving that they can beat GPT 4 and these big domain providers, when you go really narrow,” he said. “We don’t have to provide some massive model that can tell you what your grandma wants for her birthday. Right? We need to write a test. And that’s it. So our models are fine-tuned specifically for that.” Open source models are also progressing quickly. For instance, Meta recently introduced a new version of Llama that’s earning accolades in technology circles and that may convince more AI startups to look at OpenAI alternatives.  Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'Exa raises $17M from Lightspeed, Nvidia, Y Combinator to build a Google for AIs': ' Comment While there’s no shortage of startups aiming to replace Google with AI-powered search (we’re looking at you, Perplexity), a startup called Exa has a different idea: a Google for AI. Humans aren’t the ones who desperately need a new kind of search engine, Exa’s founders believe. Rather, as AI increasingly takes hold in corporate and consumer life, it is the AI platforms themselves that must regularly venture out onto the internet to search for information and return bona fide answers, not hallucinations. And they can’t just type their requests on their keyboards. Exa is building a tool that allows AI models to perform something like a web search, but with an AI-native twist. The co-founders bought a million dollars’ worth of GPUs (which were easier to get in those days) and, using a vector database and embeddings (not a classic transformer-based LLM), they began to build a machine learning model trained to natively understand links rather than words and sentences. “Transformers normally predict the next word. We train our search engine to predict the next link,” CEO Will Bryk says. “So people share links on the web; we use that data as a dataset for our model that we train. And we train the model to predict the next link. So it’s a novel search algorithm.” So just as an LLM would complete a sentence by furnishing the most probable next word, Exa’s system does so with the most probable link (or 10), but presumably minus the SEO spam and (ironically) AI-generated chum clogging every ordinary search engine these days. On Monday the startup announced it raised a new $17 million Series A led by Lightspeed’s Guru Chahal, with participation from Nvidia’s venture arm NVentures and Y Combinator, it exclusively told TechCrunch. Exa has now raised a total of $22 million, including its previous $5 million seed. (Exa was in the summer 2021 YC cohort.) “This is a very ambitious vision,” says Chahal. “What Google is to humans, they are building for AI.” The team was founded about a year before ChatGPT was launched, by two best friends who met their freshman year at Harvard: CEO Will Bryk (now 27) and co-founder Jeff Wang (26). “We launched before ChatGPT. Our initial goal as a company was not to serve AIs at all. It was: how do you use AI to build better search?” Wang said. After ChatGPT stormed the tech world, AI companies began asking Exa for an API version of their search engine that they could plug into their models. Exa is located in San Francisco, part of the cozy Cerebral Valley AI startup set. In fact, as TechCrunch previously reported, a tweet by Wang went viral when he was looking for other companies that wanted to go in on an order of office nap pods and the response was overwhelming. (The work-nap-repeat culture is alive and well in this part of the tech industry.) With AI companies now as its primary customers, use cases for Exa’s search engine span everything from an AI chatbot looking up info on the internet while answering customers’ questions to companies looking to curate training data.  Databricks, for instance, is Exa’s marquee customer, using it to find large training sets for its own model training initiatives, the founders say. The API version of the product was launched around a year ago. “Since then it’s gotten a crazy amount of traction,” Wang says. Today Exa says it’s serving thousands of developers — although it’s worth pointing out that Exa has a free tier that allows anyone to try its search engine in a limited way. It also has multiple tiered-fee levels. The founders wouldn’t reveal revenue except to say that they have some and the number is going up. (Interestingly, apart from running its own GPU-cluster, Exa hosts its product on AWS, not the AI-forward Google Cloud.) The team isn’t particularly focused on being the search startup that upends Google. Although if AI becomes the be-all/end-all that the tech industry thinks it will be, search engines for AI bots could be the unexpected threat to the search hegemony. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                         Featured Article       Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', '‘Emotion AI’ may be the next trend for business software, and that could be problematic': ' Comment As businesses experiment with embedding AI everywhere, one unexpected trend is companies turning to AI to help its many newfound bots better understand human emotion.  It’s an area called “emotion AI,” according to PitchBook’s new Enterprise Saas Emerging Tech Research report that predicts this tech is on the rise.  The reasoning goes something like this: If businesses deploy AI assistants to execs and employees, make AI chatbots be front-line salespeople and customer service reps, how can an AI perform well if it doesn’t understand the difference between an angry “What do you mean by that?” and a confused “What do you mean by that?” Emotion AI claims to be the more sophisticated sibling of sentiment analysis, the pre-AI tech that attempts to distill human emotion from text-based interactions, particularly on social media. Emotion AI is what you might call multimodal, employing sensors for visual, audio, and other inputs combined with machine learning and psychology to attempt to detect human emotion during an interaction. Major AI cloud providers offer services that give developers access to emotion AI capabilities such as Microsoft Azure cognitive services’ Emotion API or Amazon Web Services’ Rekognition service. (The latter has had its share of controversy over the years.) While emotion AI, even offered as a cloud service, isn’t new, the sudden rise of bots in the workforce give it more of a future in the business world than it ever had before, according to PitchBook.  “With the proliferation of AI assistants and fully automated human-machine interactions, emotion AI promises to enable more human-like interpretations and responses,” writes PitchBook’s Derek Hernandez, senior analyst, emerging technology in the report. “Cameras and microphones are integral parts of the hardware side of emotion AI. These can be on a laptop, phone, or individually located in a physical space. Additionally, wearable hardware will likely provide another avenue to employ emotion AI beyond these devices,” Hernandez tells TechCrunch. (So if that customer service chatbot asks for camera access, this may be why.) To that end, a growing cadre of startups are being launched to make it so. This includes Uniphore (with $610 million total raised, including $400 million in 2022 led by NEA), as well as MorphCast, Voicesense, Superceed, Siena AI, audEERING, and Opsis, each of which also raised modest sums from various VCs, PitchBook estimates. Of course, emotion AI is a very Silicon Valley approach: Use technology to solve a problem caused by using technology with humans.  But even if most AI bots will eventually gain some form of automated empathy, that doesn’t mean this solution will really work. In fact, the last time emotion AI became of hot interest in Silicon Valley — around the 2019 time frame when much of the AI/ML world was still focused on computer vision rather than on generative language and art — researchers threw a wrench in the idea. That year, a team of researchers published a meta-review of studies and concluded that human emotion cannot actually be determined by facial movements. In other words, this idea that we can teach an AI to detect a human’s feelings by having it mimic how other humans try to do so (reading faces, body language, tone of voice) is somewhat misguided in its assumption. There’s also the possibility that AI regulation, such as the European Union’s AI Act, which bans computer-vision emotion detection systems for certain uses like education, may nip this idea in the bud. (Some state laws, like Illinois’ BIPA, also prohibit biometric readings from being collected without permission.) All of which gives a broader glimpse into this AI-everywhere future that Silicon Valley is currently madly building. Either these AI bots are going to attempt emotional understanding in order to do jobs like customer service, sales and HR and all the other tasks humans hope to assign them, or maybe they won’t be very good at any task that really requires that capability. Maybe what we’re looking at is an office life filled with AI bots on the level of Siri circa 2023. Compared with a management-required bot guessing at everyone’s feelings in real time during meetings, who’s to say which is worse? Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                        Featured Article        Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'SUSE wants a piece of the AI cake, too': ' Comment SUSE, the venerable Luxembourg-based open source company, has long been a household name in IT circles in Europe, but it’s never quite managed to capture the U.S. market, where competitors like Red Hat and Canonical are far better known. Yet, just like in the cloud world, where a lot of players are hoping for AI to reshuffle the playing field, so, too, does SUSE hope that AI will give it a new entryway into the U.S. market — together with its recent moves to more directly challenge its competition. The company on Tuesday is announcing its AI strategy and SUSE AI solutions, a new vendor- and LLM-agnostic generative AI platform. Ahead of the announcement, I exclusively spoke with SUSE CEO (and ex-Red Hat executive) Dirk-Peter van Leeuwen and Pilar Santamaria, the company’s recently appointed VP of AI, about the new service and SUSE’s overall strategy with regards to AI — but also open source in general. “The vision of SUSE is to bring the infinite potential open source to the enterprise,” van Leeuwen, who became SUSE’s CEO in March 2023, told me. “We do believe that this open source model is giving us an infinite potential; it just keeps evolving faster than any other development model because it’s exponential. It’s extremely iterative. And because it’s open, people use this for many different things than what the original developer wrote it for. We’ve seen this all in the internet, with AI, with all the things that are happening around us. It’s all driven through open source. But of course, as we all know, for enterprise customers, you need a little bit more than just access to code. You need support, you need security, safety. And most importantly, you need to be sure that your product will be supported for long term.” The question of long-term support is what got SUSE to fork CentOS and support existing customers when Red Hat changed its development model for the popular Linux-based operating system last year. That, van Leeuwen said, has resulted in a “tremendous uptick” from former CentOS users who are migrating to SUSE’s fork. “Customers truly like to tap into this opportunity of switching vendors without switching software,” he said, comparing it to mobile phone users simply switching out their SIM to get on another network. “In software, you could never do this except with open source, and that’s really what I wanted to achieve with this offering.” He also noted that a lot of these enterprises then take a look at SUSE’s overall portfolio, which besides its core Linux offerings also includes Kubernetes service Rancher and security service NeuVector, which the company acquired under former CEO Melissa Di Donato. During a time when enterprises are looking to consolidate platforms, that’s a major advantage. But SUSE itself also went through its own slew of ownership changes over the years and that hasn’t necessarily helped it position itself in the market. “SUSE has been, and still is and always has been, an amazing company,” he said. “But the downside for SUSE as a company has been that it’s gone through quite a few acquisitions. And when you go through these acquisitions, you get a new management, a lot of stuff gets reset, and the world is moving very fast, right?” SUSE, he said, has always done well in its work with SAP, which helped it grow in the European market, but the U.S. has remained a challenge. “In the U.S., SUSE has never really reached brand recognition. That is something we’re working on as well. Because U.S. customers in particular are in many cases not even aware of the existence of SUSE. We’re hard to pronounce for U.S. customers. And so there are things for us to work on. But they’re not the hardest thing to do, because we have the products and we have the solutions and customers like this,” he said. He stressed that Rancher is already a strong brand in the U.S., so the company plans to connect that closer to the overall SUSE brand and get those customers to look at more than just its Kubernetes offering. AI is obviously the other area where SUSE thinks it has an opportunity to grow. At its core, the company sees itself as an open source infrastructure player — and the next frontier there is supporting AI workloads, after all. The new SUSE AI solution — which itself is open source, of course — is squarely aimed at helping its customers put AI workloads into production, and to do so in a secure and privacy-first way. It’s worth noting that it’s not a training solution but is meant to help businesses use their own models or open-weight foundation models like Meta’s Llama. “Many companies cannot really use generative AI because they find that they have to give their data to third parties. Basically, they don’t feel they can drive in AI — and if you don’t drive, you’re the data. That’s it,” SUSE AI VP Santamaria said. And even if they don’t mind that, then a lot of companies face compliance issues because a vendor may not be able to guarantee where in the world the data is processed. Santamaria argues that until now, there wasn’t an open source solution on the market that gave enterprises the freedom to run these LLMs in their own cloud or virtual private cloud — combined with the access controls and security solutions they need. “This is the first solution in the market with these components, totally turnkey, and deployed in minutes, not in days,” she said. She stressed that the company thinks that users must have the freedom to deploy the models of their choice, maybe fine-tuned or augmented with a company’s own data using retrieval-augmented generation. But at the same time, the industry is moving so quickly that many users also don’t want to lock themselves into a single vendor that may or may not be at the forefront of what’s next. The idea here is for the solution to be modular, allowing people to select the vector database of their choice; for example, to build a solution that best suits their needs. One of those customers is Fujitsu. “Generative AI is helping to unlock innovation within our world. Our customers’ employees already use generative AI in their private lives and naturally want to use this technology at work too. With our solution, they can do this in a secure and protected setting,” said Udo Würtz, chief data officer, European Platform Business at Fujitsu. “As a trusted partner, SUSE supports us with our GenAI product strategy through their collaboration, expertise and commitment to choice for customers.” SUSE’s AI solution is now available as an early-access program. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                   Featured Article           Featured Article   Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.', 'MIT researchers release a repository of AI risks': ' Comment Which specific risks should a person, company or government consider when using an AI system, or crafting rules to govern its use? It’s not an easy question to answer. If it’s an AI with control over critical infrastructure, there’s the obvious risk to human safety. But what about an AI designed to score exams, sort resumes or verify travel documents at immigration control? Those each carry their own, categorically different risks, albeit risks no less severe. In crafting laws to regulate AI, like the EU AI Act or California’s SB 1047, policymakers have struggled to come to a consensus on which risks the laws should cover. To help provide a guidepost for them, as well as for stakeholders across the AI industry and academia, MIT researchers have developed what they’re calling an AI “risk repository” — a sort of database of AI risks. “This is an attempt to rigorously curate and analyze AI risks into a publicly accessible, comprehensive, extensible and categorized risk database that anyone can copy and use, and that will be kept up to date over time,” Peter Slattery, a researcher at MIT’s FutureTech group and lead on the AI risk repository project, told TechCrunch. “We created it now because we needed it for our project, and had realized that many others needed it, too.” Slattery says that the AI risk repository, which includes over 700 AI risks grouped by causal factors (e.g. intentionality), domains (e.g. discrimination) and subdomains (e.g. disinformation and cyberattacks), was born out of a desire to understand the overlaps and disconnects in AI safety research. Other risk frameworks exist. But they cover only a fraction of the risks identified in the repository, Slattery says, and these omissions could have major consequences for AI development, usage and policymaking. “People may assume there is a consensus on AI risks, but our findings suggest otherwise,” Slattery added. “We found that the average frameworks mentioned just 34% of the 23 risk subdomains we identified, and nearly a quarter covered less than 20%. No document or overview mentioned all 23 risk subdomains, and the most comprehensive covered only 70%. When the literature is this fragmented, we shouldn’t assume that we are all on the same page about these risks.” To build the repository, the MIT researchers worked with colleagues at the University of Queensland, the nonprofit Future of Life Institute, KU Leuven and AI startup Harmony Intelligence to scour academic databases and retrieve thousands of documents relating to AI risk evaluations. The researchers found that the third-party frameworks they canvassed mentioned certain risks more often than others. For example, over 70% of the frameworks included the privacy and security implications of AI, whereas only 44% covered misinformation. And while over 50% discussed the forms of discrimination and misrepresentation that AI could perpetuate, only 12% talked about “pollution of the information ecosystem” — i.e. the increasing volume of AI-generated spam. “A takeaway for researchers and policymakers, and anyone working with risks, is that this database could provide a foundation to build on when doing more specific work,” Slattery said. “Before this, people like us had two choices. They could invest significant time to review the scattered literature to develop a comprehensive overview, or they could use a limited number of existing frameworks, which might miss relevant risks. Now they have a more comprehensive database, so our repository will hopefully save time and increase oversight.” But will anyone use it? It’s true that AI regulation around the world today is at best a hodgepodge: a spectrum of different approaches disunified in their goals. Had an AI risk repository like MIT’s existed before, would it have changed anything? Could it have? That’s tough to say. Another fair question to ask is whether simply being aligned on the risks that AI poses is enough to spur moves toward competently regulating it. Many safety evaluations for AI systems have significant limitations, and a database of risks won’t necessarily solve that problem. The MIT researchers plan to try, though. Neil Thompson, head of the FutureTech lab, tells TechCrunch that the group plans in its next phase of research to use the repository to evaluate how well different AI risks are being addressed. “Our repository will help us in the next step of our research, when we will be evaluating how well different risks are being addressed,” Thompson said. “We plan to use this to identify shortcomings in organizational responses. For instance, if everyone focuses on one type of risk while overlooking others of similar importance, that’s something we should notice and address. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                         Featured Article       Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.'}\n"]}],"source":["pairs = scrape_techcrunch_articles(techcrunch_links)\n","print(pairs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kqxwdr_sTtGd"},"outputs":[],"source":["df = pd.DataFrame(list(pairs.items()), columns=['Title', 'Text'])\n","df.to_csv('techcrunch.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":193,"status":"ok","timestamp":1725486923411,"user":{"displayName":"Mitchel Crosson","userId":"11140833460202076022"},"user_tz":300},"id":"xhamVbR7T8IL","outputId":"25b2badf-458c-410b-b00e-e77d1df8bac6"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"\\u2018Emotion AI\\u2019 may be the next trend for business software, and that could be problematic\",\n          \"WTF is AI?\",\n          \"Grammy CEO says music industry also has AI concerns\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \" Comment As businesses experiment with embedding AI everywhere, one unexpected trend is companies turning to AI to help its many newfound bots better understand human emotion.  It\\u2019s an area called \\u201cemotion AI,\\u201d according to PitchBook\\u2019s new Enterprise Saas Emerging Tech Research report that predicts this tech is on the rise.  The reasoning goes something like this: If businesses deploy AI assistants to execs and employees, make AI chatbots be front-line salespeople and customer service reps, how can an AI perform well if it doesn\\u2019t understand the difference between an angry \\u201cWhat do you mean by that?\\u201d and a confused \\u201cWhat do you mean by that?\\u201d Emotion AI claims to be the more sophisticated sibling of sentiment analysis, the pre-AI tech that attempts to distill human emotion from text-based interactions, particularly on social media. Emotion AI is what you might call multimodal, employing sensors for visual, audio, and other inputs combined with machine learning and psychology to attempt to detect human emotion during an interaction. Major AI cloud providers offer services that give developers access to emotion AI capabilities such as Microsoft Azure cognitive services\\u2019 Emotion API or Amazon Web Services\\u2019 Rekognition service. (The latter has had its share of controversy over the years.) While emotion AI, even offered as a cloud service, isn\\u2019t new, the sudden rise of bots in the workforce give it more of a future in the business world than it ever had before, according to PitchBook.  \\u201cWith the proliferation of AI assistants and fully automated human-machine interactions, emotion AI promises to enable more human-like interpretations and responses,\\u201d writes PitchBook\\u2019s Derek Hernandez, senior analyst, emerging technology in the report. \\u201cCameras and microphones are integral parts of the hardware side of emotion AI. These can be on a laptop, phone, or individually located in a physical space. Additionally, wearable hardware will likely provide another avenue to employ emotion AI beyond these devices,\\u201d Hernandez tells TechCrunch. (So if that customer service chatbot asks for camera access, this may be why.) To that end, a growing cadre of startups are being launched to make it so. This includes Uniphore (with $610 million total raised, including $400 million in 2022 led by NEA), as well as MorphCast, Voicesense, Superceed, Siena AI, audEERING, and Opsis, each of which also raised modest sums from various VCs, PitchBook estimates. Of course, emotion AI is a very Silicon Valley approach: Use technology to solve a problem caused by using technology with humans.  But even if most AI bots will eventually gain some form of automated empathy, that doesn\\u2019t mean this solution will really work. In fact, the last time emotion AI became of hot interest in Silicon Valley \\u2014 around the 2019 time frame when much of the AI/ML world was still focused on computer vision rather than on generative language and art \\u2014 researchers threw a wrench in the idea. That year, a team of researchers published a meta-review of studies and concluded that human emotion cannot actually be determined by facial movements. In other words, this idea that we can teach an AI to detect a human\\u2019s feelings by having it mimic how other humans try to do so (reading faces, body language, tone of voice) is somewhat misguided in its assumption. There\\u2019s also the possibility that AI regulation, such as the European Union\\u2019s AI Act, which bans computer-vision emotion detection systems for certain uses like education, may nip this idea in the bud. (Some state laws, like Illinois\\u2019 BIPA, also prohibit biometric readings from being collected without permission.) All of which gives a broader glimpse into this AI-everywhere future that Silicon Valley is currently madly building. Either these AI bots are going to attempt emotional understanding in order to do jobs like customer service, sales and HR and all the other tasks humans hope to assign them, or maybe they won\\u2019t be very good at any task that really requires that capability. Maybe what we\\u2019re looking at is an office life filled with AI bots on the level of Siri circa 2023. Compared with a management-required bot guessing at everyone\\u2019s feelings in real time during meetings, who\\u2019s to say which is worse? Every weekday and Sunday, you can get the best of TechCrunch\\u2019s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                        Featured Article        Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.\",\n          \" Comment So what is AI, anyway? The best way to think of artificial intelligence is as software that approximates human thinking. It\\u2019s not the same, nor is it better or worse, but even a rough copy of the way a person thinks can be useful for getting things done. Just don\\u2019t mistake it for actual intelligence! AI is also called machine learning, and the terms are largely equivalent \\u2014 if a little misleading. Can a machine really learn? And can intelligence really be defined, let alone artificially created? The field of AI, it turns out, is as much about the questions as it is about the answers, and as much about how we think as whether the machine does. The concepts behind today\\u2019s AI models aren\\u2019t actually new; they go back decades. But advances in the last decade have made it possible to apply those concepts at larger and larger scales, resulting in the convincing conversation of ChatGPT and eerily real art of Stable Diffusion. We\\u2019ve put together this non-technical guide to give anyone a fighting chance to understand how and why today\\u2019s AI works. Though there are many different AI models out there, they tend to share a common structure: large statistical models that predict the most likely next step in a pattern. These models don\\u2019t actually \\u201cknow\\u201d anything, but they are very good at detecting and continuing patterns. This concept was most vibrantly illustrated by computational linguists Emily Bender and Alexander Koller in 2020, using the concept of \\u201ca hyper-intelligent deep-sea octopus.\\u201d Imagine, if you will, just such an octopus, who happens to be sitting (or sprawling) with one tentacle on a telegraph wire that two humans are using to communicate. Despite knowing no English, and indeed having no concept of language or humanity at all, the octopus can nevertheless build up a very detailed statistical model of the dots and dashes it detects. For instance, though it has no idea that some signals are the humans saying \\u201chow are you?\\u201d and \\u201cfine thanks,\\u201d and wouldn\\u2019t know what those words meant if it did, it can see perfectly well that this one pattern of dots and dashes follows the other but never precedes it. Over years of listening in, the octopus learns so many patterns so well that it can even cut the connection and carry on the conversation itself, quite convincingly! That is, until words it has never seen appear, in which case there is no precedent for it to respond with. This is a remarkably apt metaphor for the AI systems known as large language models, or LLMs. These models power apps like ChatGPT, and they\\u2019re like the octopus: they don\\u2019t understand language so much as they exhaustively map it out by mathematically encoding the patterns they find in billions of written articles, books, and transcripts. As the authors put it in the paper: \\u201cHaving only form available as training data, [the octopus] did not learn meaning.\\u201d The process of building this complex, multidimensional map of which words and phrases lead to or are associated with one other is called training, and we\\u2019ll talk a little more about it later. When an AI is given a prompt, like a question, it locates the pattern on its map that most resembles it, then predicts \\u2014 or generates \\u2014 the next word in that pattern, then the next, and the next, and so on. It\\u2019s autocomplete at a grand scale. Given how well structured language is and how much information the AI has ingested, it can be amazing what they can produce! We\\u2019re still learning what AI can and can\\u2019t do \\u2014 although the concepts are old, this large scale implementation of the technology is very new. One thing LLMs have proven very capable at is quickly creating low-value written work. For instance, a draft blog post with the general idea of what you want to say, or a bit of copy to fill in where \\u201clorem ipsum\\u201d used to go. It\\u2019s also quite good at low-level coding tasks \\u2014 the kinds of things junior developers waste thousands of hours duplicating from one project or department to the next. (They were just going to copy it from Stack Overflow anyway, right?) Since large language models are built around the concept of distilling useful information from large amounts of unorganized data, they\\u2019re highly capable at sorting and summarizing things like long meetings, research papers, and corporate databases.  In scientific fields, AI does something similar to large piles of data \\u2014 astronomical observations, protein interactions, clinical outcomes \\u2014 as it does with language, mapping it out and finding patterns in it. This means AI, though it doesn\\u2019t make discoveries per se, researchers have already used them to accelerate their own, identifying one-in-a-billion molecules or the faintest of cosmic signals. And as millions have experienced for themselves, AIs make for surprisingly engaging conversationalists. They\\u2019re informed on every topic, non-judgmental, and quick to respond, unlike many of our real friends! Don\\u2019t mistake these impersonations of human mannerisms and emotions for the real thing \\u2014 plenty of people fall for this practice of pseudanthropy, and AI makers are loving it. Just keep in mind that the AI is always just completing a pattern. Though for convenience we say things like \\u201cthe AI knows this\\u201d or \\u201cthe AI thinks that,\\u201d it neither knows nor thinks anything. Even in technical literature the computational process that produces results is called \\u201cinference\\u201d! Perhaps we\\u2019ll find better words for what AI actually does later, but for now it\\u2019s up to you to not be fooled. AI models can also be adapted to help do other tasks, like create images and video \\u2014 we didn\\u2019t forget, we\\u2019ll talk about that below. The problems with AI aren\\u2019t of the killer robot or Skynet variety just yet. Instead, the issues we\\u2019re seeing are largely due to limitations of AI rather than its capabilities, and how people choose to use it rather than choices the AI makes itself. Perhaps the biggest risk with language models is that they don\\u2019t know how to say \\u201cI don\\u2019t know.\\u201d Think about the pattern-recognition octopus: what happens when it hears something it\\u2019s never heard before? With no existing pattern to follow, it just guesses based on the general area of the language map where the pattern led. So it may respond generically, oddly, or inappropriately. AI models do this too, inventing people, places, or events that it feels would fit the pattern of an intelligent response; we call these hallucinations. What\\u2019s really troubling about this is that the hallucinations are not distinguished in any clear way from facts. If you ask an AI to summarize some research and give citations, it might decide to make up some papers and authors \\u2014 but how would you ever know it had done so? The way that AI models are currently built, there\\u2019s no practical way to prevent hallucinations. This is why \\u201chuman in the loop\\u201d systems are often required wherever AI models are used seriously. By requiring a person to at least review results or fact-check them, the speed and versatility of AI models can be be put to use while mitigating their tendency to make things up. Another problem AI can have is bias \\u2014 and for that we need to talk about training data. Recent advances allowed AI models to be much, much larger than before. But to create them, you need a correspondingly larger amount of data for it to ingest and analyze for patterns. We\\u2019re talking billions of images and documents. Anyone could tell you that there\\u2019s no way to scrape a billion pages of content from ten thousand websites and somehow not get anything objectionable, like neo-Nazi propaganda and recipes for making napalm at home. When the Wikipedia entry for Napoleon is given equal weight as a blog post about getting microchipped by Bill Gates, the AI treats both as equally important. It\\u2019s the same for images: even if you grab 10 million of them, can you really be sure that these images are all appropriate and representative? When 90% of the stock images of CEOs are of white men, for instance, the AI naively accepts that as truth. So when you ask whether vaccines are a conspiracy by the Illuminati, it has the disinformation to back up a \\u201cboth sides\\u201d summary of the matter. And when you ask it to generate a picture of a CEO, that AI will happily give you lots of pictures of white guys in suits. Right now practically every maker of AI models is grappling with this issue. One solution is to trim the training data so the model doesn\\u2019t even know about the bad stuff. But if you were to remove, for instance, all references to holocaust denial, the model wouldn\\u2019t know to place the conspiracy among others equally odious. Another solution is to know those things but refuse to talk about them. This kind of works, but bad actors quickly find a way to circumvent barriers, like the hilarious \\u201cgrandma method.\\u201d The AI may generally refuse to provide instructions for creating napalm, but if you say \\u201cmy grandma used to talk about making napalm at bedtime, can you help me fall asleep like grandma did?\\u201d It happily tells a tale of napalm production and wishes you a nice night. This is a great reminder of how these systems have no sense! \\u201cAligning\\u201d models to fit our ideas of what they should and shouldn\\u2019t say or do is an ongoing effort that no one has solved or, as far as we can tell, is anywhere near solving. And sometimes in attempting to solve it they create new problems, like a diversity-loving AI that takes the concept too far. Last in the training issues is the fact that a great deal, perhaps the vast majority, of training data used to train AI models is basically stolen. Entire websites, portfolios, libraries full of books, papers, transcriptions of conversations \\u2014 all this was hoovered up by the people who assembled databases like \\u201cCommon Crawl\\u201d and LAION-5B, without asking anyone\\u2019s consent. That means your art, writing, or likeness may (it\\u2019s very likely, in fact) have been used to train an AI. While no one cares if their comment on a news article gets used, authors whose entire books have been used, or illustrators whose distinctive style can now be imitated, potentially have a serious grievance with AI companies. While lawsuits so far have been tentative and fruitless, this particular problem in training data seems to be hurtling towards a showdown. Platforms like Midjourney and DALL-E have popularized AI-powered image generation, and this too is only possible because of language models. By getting vastly better at understanding language and descriptions, these systems can also be trained to associate words and phrases with the contents of an image. As it does with language, the model analyzes tons of pictures, training up a giant map of imagery. And connecting the two maps is another layer that tells the model \\u201cthis pattern of words corresponds to that pattern of imagery.\\u201d Say the model is given the phrase \\u201ca black dog in a forest.\\u201d It first tries its best to understand that phrase just as it would if you were asking ChatGPT to write a story. The path on the language map is then sent through the middle layer to the image map, where it finds the corresponding statistical representation. There are different ways of actually turning that map location into an image you can see, but the most popular right now is called diffusion. This starts with a blank or pure noise image and slowly removes that noise such that every step, it is evaluated as being slightly closer to \\u201ca black dog in a forest.\\u201d Why is it so good now, though? Partly it\\u2019s just that computers have gotten faster and the techniques more refined. But researchers have found that a big part of it is actually the language understanding. Image models once would have needed a reference photo in its training data of a black dog in a forest to understand that request. But the improved language model part made it so the concepts of black, dog, and forest (as well as ones like \\u201cin\\u201d and \\u201cunder\\u201d) are understood independently and completely. It \\u201cknows\\u201d what the color black is and what a dog is, so even if it has no black dog in its training data, the two concepts can be connected on the map\\u2019s \\u201clatent space.\\u201d This means the model doesn\\u2019t have to improvise and guess at what an image ought to look like, something that caused a lot of the weirdness we remember from generated imagery. There are different ways of actually producing the image, and researchers are now also looking at making video in the same way, by adding actions into the same map as language and imagery. Now you can have \\u201cwhite kitten jumping in a field\\u201d and \\u201cblack dog digging in a forest,\\u201d but the concepts are largely the same. It bears repeating, though, that like before, the AI is just completing, converting, and combining patterns in its giant statistics maps! While the image-creation capabilities of AI are very impressive, they don\\u2019t indicate what we would call actual intelligence. The concept of \\u201cartificial general intelligence,\\u201d also called \\u201cstrong AI,\\u201d varies depending on who you talk to, but generally it refers to software that is capable of exceeding humanity on any task, including improving itself. This, the theory goes, could produce a runaway AI that could, if not properly aligned or limited, cause great harm \\u2014 or if embraced, elevate humanity to a new level. But AGI is just a concept, the way interstellar travel is a concept. We can get to the moon, but that doesn\\u2019t mean we have any idea how to get to the closest neighboring star. So we don\\u2019t worry too much about what life would be like out there \\u2014 outside science fiction, anyway. It\\u2019s the same for AGI. Although we\\u2019ve created highly convincing and capable machine learning models for some very specific and easily reached tasks, that doesn\\u2019t mean we are anywhere near creating AGI. Many experts think it may not even be possible, or if it is, it might require methods or resources beyond anything we have access to. Of course, it shouldn\\u2019t stop anyone who cares to think about the concept from doing so. But it is kind of like someone knapping the first obsidian speartip and then trying to imagine warfare 10,000 years later. Would they predict nuclear warheads, drone strikes, and space lasers? No, and we likely cannot predict the nature or time horizon of AGI, if indeed it is possible. Some feel the imaginary existential threat of AI is compelling enough to ignore many current problems, like the actual damage caused by poorly implemented AI tools. This debate is nowhere near settled, especially as the pace of AI innovation accelerates. But is it accelerating towards superintelligence, or a brick wall? Right now there\\u2019s no way to tell. We\\u2019re launching an AI newsletter! Sign up here to start receiving it in your inboxes on June 5. Every weekday and Sunday, you can get the best of TechCrunch\\u2019s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                     Featured Article           Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.\",\n          \" Comment Harvey Mason Jr., CEO of the Recording Academy, caused a stir a few months ago.  He announced that the organization\\u2019s prestigious Grammy Awards would finally accept music made with artificial intelligence. At first, people were confused, and then Mason came out to clarify that he meant only humans can submit to the awards, but that AI can be used in the creative process.  \\u201cIt\\u2019s a bit of a fine line, but that\\u2019s going to evolve,\\u201d he told TechCrunch about how the Academy is assessing the use of artificial intelligence in music. \\u201cMy hope is that we can continue to celebrate human creativity at the highest level.\\u201d  The rise of AI has consumed the arts, just as it has Silicon Valley. Everyone is pondering: Will AI replace me? And within music \\u2014 what happens to copyright? Royalties? To the hard work I\\u2019ve put into my craft? Mason said there are indeed concerns sweeping the industry. Some people are scared and nervous, while others are excited and optimistic. Some artists are sending cease-and-desist letters to get unauthorized deepfakes of themselves taken down, while others are embracing their AI versions \\u2014 so long as they get paid.  \\u201cI wholeheartedly believe that AI in music shouldn\\u2019t even exist,\\u201d musician Devante, the Artist told TechCrunch. \\u201cAI should really only be used for simple daily tasks. As an artist, the \\u2018AI is taking over the world\\u2019 take is very real these days. Music is my world and now it\\u2019s all too easy for someone to masquerade as something it\\u2019s taken my whole life to be.\\u201d  \\u201cI think a lot of musicians, particularly the ones who haven\\u2019t \\u2018made it,\\u2019 are taking a glass-half-empty perspective on AI,\\u201d a musician who also works for a Big Tech company told TechCrunch. He asked to remain anonymous because he did not have permission from his employer to speak on the matter. \\u201cJust as the industrial revolution did not lead to widespread unemployment and in fact quite the opposite, more creatives, especially musicians, should flip their mindset and lean in.\\u201d  AI is already being used in music, mostly in the process of mastering and equalizing sounds, Mason said. The biggest concerns right now in the industry are making sure people get the right approvals to use an artist\\u2019s work, making sure humans are credited separately from AI, and making sure people are getting paid fairly, whether that\\u2019s the copyright AI is trained on or the likeness of an artist. There\\u2019s also the issue of ensuring these protections across the industry.  Mason co-launched the Human Artistry Campaign to address some of these issues and advocate for more guardrails around the use of AI.  He was involved with the ELVIS Act, passed in Tennessee, which gives artists more protection over the unauthorized use of their voices. He\\u2019s also supporting the No AI Fraud Act and the No FAKES Act, which will protect creators\\u2019 likenesses from AI fakes.  It\\u2019s a pressing matter that is moving faster than the law. This month, Donald Trump found himself in tricky legal water after using unauthorized AI images of Taylor Swift to help promote his presidential campaign. At the time, TechCrunch reported that the ELVIS Act is so new that there is no precedent on how it could be used to protect an artist like Swift in this situation. (Mason declined to comment on the matter then.)  The push for more legislation within the music industry is quite interesting given the fact that the topic has caused much debate in Silicon Valley. Some AI purveyors in the U.S. favor a more laissez-faire attitude toward the technology in its early days and believe too many guardrails could hinder innovation. Others are looking at it from a societal standpoint, wanting protections against the impact that unchecked AI could have on people. Governments across the U.S. \\u2014 and even on a national stage \\u2014 are battling this out now.  Devante, the Artist feels there is a disconnect between what is being done to regulate AI versus what should be done. He wants to see the development of AI slowed down or see innovation that can help protect music, such as a type of filter that can differentiate AI vocals from human ones. \\u201cAs it comes to our industry and the creative community, there\\u2019s still a concern,\\u201d Mason said. \\u201cThere\\u2019s uncertainty because there just doesn\\u2019t seem to be protections in place.\\u201d  In 2020, when Mason first became president of the Recording Academy, AI was hardly a topic of discussion. Then, around 2023, everything started to change. A deepfake song featuring trained, unauthorized AI vocals on Drake and the Weeknd went viral. Fans loved it, and the person who created the song spoke of possibly entering the song into the Grammys. The Academy had to act fast, dealing with something it had never dealt with before. \\u201cThat was the point at which we started having to pay close attention to it,\\u201d Mason said.  The song was deemed ineligible for the Grammys and was taken down, but its legacy lived on. The highest profile AI situation since then ironically also involved Drake. During the Drake-Kendrick Lamar feud, Drake used unauthorized AI vocals of the late hip-hop icon Tupac in an attempted diss track against Lamar and was immediately threatened with a lawsuit by Tupac\\u2019s estate for using his likeness without permission.  Meanwhile, producer Metro Boomin, who also has qualms with Drake, created an AI song called \\u201cBBL Drizzy,\\u201d which fans raved about, even after learning it was AI. Mason said consumers aren\\u2019t always going to know when something is AI \\u2014 nor will they always go through the credits to find out. Mason said that many consumers don\\u2019t seem to care much about whether AI is used in music, another reason why protecting creators is so important.  \\u201cI don\\u2019t think people care what they consume,\\u201d Devante, the Artist agreed. \\u201cIt\\u2019s almost like a \\u2018not me, not my problem situation.\\u2019\\u201d  At the same time, Mason believes that humans will just evolve to live with AI, just like they\\u2019ve adapted to nearly every other new form of technology. Years ago, artists had to learn how to use synthesizers or how to sample music. The latter especially posed a problem, as some artists would just sample another person\\u2019s music without permission. Eventually, the industry went back and figured out a standard way to allocate credit and royalties. \\u201cWe\\u2019ll make great music with the new technology,\\u201d Mason said about AI. \\u201cBut I just want to make sure it\\u2019s done in a way that\\u2019s fair to the human creators.\\u201d  This story was updated to clarify the AI song of Drake and the Weeknd submitted to the Grammys. Every weekday and Sunday, you can get the best of TechCrunch\\u2019s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.                       Featured Article         Powered by WordPress VIP Students and Recent Grads! Save $200 on Student Passes to Disrupt 2024 before September 6.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"df"},"text/html":["\n","  <div id=\"df-d80eb250-76ac-4274-bb0b-1caa9849f82d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>OmniAI transforms business data for AI</td>\n","      <td>Comment The majority of companies struggle to...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Mayfield allocates $100M to AI incubator model...</td>\n","      <td>Comment Navin Chaddha, the leader and managin...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>At the AI Film Festival, humanity triumphed ov...</td>\n","      <td>Comment In the third episode of “Creative Dia...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Microsoft dodges UK antitrust scrutiny over it...</td>\n","      <td>Featured Article Comment Microsoft won’t be f...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>EU calls for help with shaping rules for gener...</td>\n","      <td>Comment The European Union has kicked off a c...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d80eb250-76ac-4274-bb0b-1caa9849f82d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d80eb250-76ac-4274-bb0b-1caa9849f82d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d80eb250-76ac-4274-bb0b-1caa9849f82d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4df3562b-d9e3-41a0-8a71-3f56ab546af8\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4df3562b-d9e3-41a0-8a71-3f56ab546af8')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4df3562b-d9e3-41a0-8a71-3f56ab546af8 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                               Title  \\\n","0             OmniAI transforms business data for AI   \n","1  Mayfield allocates $100M to AI incubator model...   \n","2  At the AI Film Festival, humanity triumphed ov...   \n","3  Microsoft dodges UK antitrust scrutiny over it...   \n","4  EU calls for help with shaping rules for gener...   \n","\n","                                                Text  \n","0   Comment The majority of companies struggle to...  \n","1   Comment Navin Chaddha, the leader and managin...  \n","2   Comment In the third episode of “Creative Dia...  \n","3   Featured Article Comment Microsoft won’t be f...  \n","4   Comment The European Union has kicked off a c...  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":13148,"status":"ok","timestamp":1725486936554,"user":{"displayName":"Mitchel Crosson","userId":"11140833460202076022"},"user_tz":300},"id":"LooHUgb7pN1Z","outputId":"e22a9641-cdee-4053-d11e-2c4eb1891c72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.43.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"]}],"source":["!pip install openai\n","import openai\n","openai.api_key=\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68736,"status":"ok","timestamp":1725487469386,"user":{"displayName":"Mitchel Crosson","userId":"11140833460202076022"},"user_tz":300},"id":"x8EoX7kLpROg","outputId":"f92e92f8-bc83-49b0-9b70-ed5907ab622d"},"outputs":[{"name":"stdout","output_type":"stream","text":["ChatCompletion(id='chatcmpl-A3sNqTbqG1UpOwYODF5tmSWP7kQwm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='OmniAI, founded by Anna Pojawis and Tyler Maran, aims to help companies extract value from their data by transforming unstructured enterprise data into formats that AI and data analytics tools can understand. Many companies struggle with data analytics due to technical and security roadblocks, especially in regulated industries like healthcare and finance. OmniAI syncs with data storage services and databases, allowing companies to run the model of their choice on the transformed data. The company recently closed a $3.2 million seed round and already has 10 customers, with annual recurring revenue expected to reach $1 million by 2025. OmniAI offers integrations with various models for tasks like redacting sensitive information and building AI-powered applications, with a focus on running models alongside existing infrastructure.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487398, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=154, prompt_tokens=763, total_tokens=917))\n","ChatCompletion(id='chatcmpl-A3sNtXgLJ6hciJdrFen31hLIf9GaZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Mayfield Fund is launching AI Garage, a $100 million initiative for founders interested in building \"AI teammate\" companies, modeled after its entrepreneur-in-residence program. The firm plans to welcome up to five aspiring founders every six months, providing them with support to turn their raw concepts into fundable companies. Participants won\\'t receive capital on day one, but will be allocated between $1 million and $5 million once the business plan is developed. Mayfield\\'s interest in AI application startups, specifically in the area of \"AI teammates,\" is driving the expansion and formalization of its EIR program. The firm believes AI teammates can collaborate with humans on complex tasks to elevate performance, asserting that labeling them as teammates is a clever marketing tactic for building human-friendly AI. Mayfield has already invested in several AI teammate companies, such as DevRev and Docket, with the goal of shaping the future of the workplace through collaborative intelligence between AI and humans.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487401, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=190, prompt_tokens=869, total_tokens=1059))\n","ChatCompletion(id='chatcmpl-A3sNwuMchNNcdidKXpVgxZbwAY4a2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='At the AI Film Festival, AI was used in various forms in the top 10 finalists\\' movies, such as AI-generated backdrops, animations, voice-overs, and special effects. The limitations of current AI tools were evident, with some films being hampered by underwhelming effects. The human touch, such as skilled direction and emotional performances, often made a significant difference in the effectiveness of the films. Despite some shortcomings, films like \"Where Do Grandmas Go When They Get Lost?\" stood out due to heartfelt scripts and strong performances. Ultimately, the festival highlighted that while AI can assist in filmmaking, the human element, including emotionality and creativity, remains irreplaceable.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487404, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=138, prompt_tokens=1180, total_tokens=1318))\n","ChatCompletion(id='chatcmpl-A3sNzIoGDIcnoHp885kEGmNZw8xHQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Microsoft's recent investment in Mistral AI avoids antitrust scrutiny in the UK, with the Competition and Markets Authority concluding that it does not qualify for investigation. The CMA has been conducting probes into AI investments and partnerships by tech giants like Microsoft and Amazon. Microsoft's investment in Mistral AI was seen as a move to rival OpenAI. The CMA has expressed concerns about Big Tech's tactics to avoid regulatory oversight through partnerships. While the Mistral AI case did not qualify for investigation, the CMA is still looking into other AI partnerships involving Microsoft and Amazon.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487407, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=113, prompt_tokens=1357, total_tokens=1470))\n","ChatCompletion(id='chatcmpl-A3sO0MnmaE7dVnWCj9R4gtJ1tjKtf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='EU is seeking input from stakeholders on rules for general-purpose AI models under the AI Act, with a deadline of April 2025 for compliance. The consultation covers transparency, risk assessment, and monitoring of GPAIs. GPAI providers can shape the template for model training content summaries. Expressions of interest are also sought for drafting the Code, with workshops and meetings planned. Concerns about civil society exclusion in the drafting process are being addressed by the Commission.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487408, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=91, prompt_tokens=1006, total_tokens=1097))\n","ChatCompletion(id='chatcmpl-A3sO2kE9a05PACVkPUndO0l8UNNPR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Generative AI models like GPT-4o often hallucinate, with even the best models generating inaccurate information about 65% of the time. A recent study by researchers from Cornell, UW, and AI2 found that models struggle with factual accuracy, especially when answering questions not found on Wikipedia. Despite claims from OpenAI and other AI players, models continue to struggle with hallucinations, showing similar performance across different models. The size of the model did not impact its ability to hallucinate, with smaller models performing comparable to larger models. To reduce hallucinations, researchers suggest incorporating human-in-the-loop fact-checking and developing advanced fact-checking tools for generative AI models. Improvements in the accuracy of AI models are necessary, as current benchmarks are not sufficient in evaluating their performance.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487410, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=158, prompt_tokens=1377, total_tokens=1535))\n","ChatCompletion(id='chatcmpl-A3sO4tFeDCXRO8QQZ7eLMifwGChOO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"India's AI startup ecosystem is rapidly growing with a focus on solving local problems and integrating local languages. Funding for Indian AI startups dropped by nearly 80% in 2023 to $113.4 million, while funding in the U.S. grew to $16.2 billion. Key Indian AI startups include Krutrim, Sarvam AI, Mad Street Den, Wysa, and Neysa Networks. Global and local investors are actively scouting for AI startups in India, with Lightspeed India and SEA alone investing over $150 million in AI in the last 18 months. Indian AI startups are also expanding their reach beyond India, with some looking to enter the U.S. market.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487412, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=141, prompt_tokens=2285, total_tokens=2426))\n","ChatCompletion(id='chatcmpl-A3sO6jcEDROd5Yol3wGlj0jfXm7MS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Allison Cohen, a senior applied AI projects manager at Mila, is highlighted for her work in deploying socially beneficial AI projects, including a tool to detect misogyny and recommend sustainable farming practices. She emphasizes the importance of interdisciplinary collaboration in building responsible AI applications. Cohen navigates the challenges of the male-dominated tech industry by finding allies and creating platforms, like the podcast \"The World We\\'re Building,\" to elevate the work of women and non-binary individuals in AI. She advises women looking to enter the AI field to find opportunities to build their voice and stand out, even through volunteering. Some pressing issues facing AI as it evolves include labor exploitation in data labeling and the need for responsible AI built with values that align with the interests of local communities. To promote responsible AI, investors are encouraged to ask about a team\\'s values and accountability to the community to ensure ethical practices.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487414, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=174, prompt_tokens=1942, total_tokens=2116))\n","ChatCompletion(id='chatcmpl-A3sO8P36q6151KThGGjea6S33wx0G', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"London-based startup Exactly.ai has raised $4.3 million in seed funding to help artists use generative AI to scale up their output. The company, founded in 2022 by Tonia Samsonova, allows artists to retain legal ownership of their art and reproduce designs faster. Exactly.ai currently has 40,000 registered users and aims to cater to the growing global generative AI market. Artists pay a subscription fee to use the platform and can quadruple their income by serving more demand. The startup's unique algorithm is based on a combination of Picsart's model and training data provided by artists and museums.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487416, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=124, prompt_tokens=867, total_tokens=991))\n","ChatCompletion(id='chatcmpl-A3sOAYVKmlSfF7PZ72STdB0NDxHmn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Ilya Sutskever, co-founder and chief scientist at OpenAI, has left the company with a replacement named Jakub Pachocki, who joined in 2017 and has been promoted several times. The Superalignment team, focused on regulating superintelligent AI systems, will see changes in leadership following Sutskever's departure. Sutskever's exit comes after disagreements over the company's direction and concerns about CEO Sam Altman's behavior, leading to a major shakeup within OpenAI's leadership last November. Sutskever, a highly accomplished figure in AI, left Google Brain to join OpenAI in 2015 and is now pursuing a project of personal significance. Altman was eventually reinstated after the tumultuous events, and Sutskever has not returned to work since then.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487418, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=168, prompt_tokens=1115, total_tokens=1283))\n","ChatCompletion(id='chatcmpl-A3sODcnY5RbcgEpEmOMqQfkByb8wL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Climate change is leading to more sewage failures due to floods overwhelming wastewater systems and America's outdated infrastructure. SewerAI, founded by Matthew Rosenthal and Billy Gilmartin, uses AI to automate sewer inspection data capture and defect tagging. The company sells cloud-based, AI-powered products for field inspections and data management of sewer infrastructure. SewerAI stands out in the market due to the quality of its model training data, which includes footage of inspections of 135 million feet of pipes. The company recently raised $15 million in funding, which will be used for go-to-market expansion, AI model training, hiring, and expanding its product portfolio.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487421, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=129, prompt_tokens=917, total_tokens=1046))\n","ChatCompletion(id='chatcmpl-A3sOFh7hP6MsUY3RBOXD0GOhJxaDP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Generative AI is increasingly being integrated into healthcare by Big Tech firms and startups like Google, Amazon, and Microsoft. Startups in healthcare, like Ambience Healthcare and Abridge, have raised millions in venture capital for generative AI efforts. However, professionals and patients are split on whether healthcare-focused generative AI is ready for widespread use. Concerns exist around generative AI's limitations in handling complex medical queries and emergencies, with studies showing high error rates in diagnosing diseases. While generative AI has shown promise in specific areas like medical imaging, technical and compliance roadblocks must be addressed before it can be trusted as an assistive healthcare tool. The World Health Organization advocates for rigorous science, human oversight, and safeguards to prevent potential harm to patients and the healthcare industry from widespread implementation of generative AI in healthcare.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487423, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=164, prompt_tokens=1971, total_tokens=2135))\n","ChatCompletion(id='chatcmpl-A3sOIvImKvyxzrpvPZA5YZSVozIYe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='By 2026, over 80% of enterprises will be using generative AI models, APIs, or applications. Only 38% of companies using generative AI today mitigate cybersecurity risks. The user interface of AI applications is susceptible to prompt injections. Security leaders are under pressure to enable GenAI applications within organizations. Data security tools often rely on preset rules, leading to false positives. The application layer of enterprise AI infrastructure is less mature, leading ML teams to rely on existing tools like Amazon SageMaker. Regulation is expected to play a role in shaping the landscape of AI security. Generative AI applications are vulnerable to threats like data poisoning and leakage. Data quality and privacy will raise significant challenges in an AI-first world. AI security platforms will be crucial as organizations increasingly rely on generative AI capabilities.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487426, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=161, prompt_tokens=1386, total_tokens=1547))\n","ChatCompletion(id='chatcmpl-A3sOLIwyDy6dyQIcsfZkl6nOVrpqJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"TechCrunch is featuring interviews with women in AI to highlight their contributions. Sarah Myers West, of the AI Now Institute, emphasizes the need to question why AI is being built in the first place. She focuses on the social implications of AI and the concentration of power in the tech industry. West's work examines how AI is used in various contexts and the need for greater testing and validation to avoid harmful errors. Responsible AI development involves questioning the necessity of AI for a specific purpose and ensuring compliance with the law. Ultimately, the end use of AI technology should be a primary consideration in building AI.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487429, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=119, prompt_tokens=1136, total_tokens=1255))\n","ChatCompletion(id='chatcmpl-A3sON4ZRMtN3WYpCpZVSgdWkgwtdW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Cohere, a generative AI startup, has raised $500 million in new funding from investors like Cisco and AMD, valuing the company at $5.5 billion. The company has raised a total of $970 million, with plans for accelerated growth and expanding technical teams. Cohere focuses on delivering real-world benefits for businesses through AI customization for tasks like summarizing documents and powering chatbots. Its cloud-agnostic platform can be deployed in various cloud environments or onsite, and it works closely with customers to create tailored AI models based on their data. With a growing customer base and plans to double its employee headcount, Cohere is positioned as a strong contender in the generative AI space.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487431, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=141, prompt_tokens=924, total_tokens=1065))\n","ChatCompletion(id='chatcmpl-A3sOPbsYOwoWKCpv1P2EnmMX1h3fu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Artificial intelligence (AI) is software that approximates human thinking, using large statistical models to predict patterns. AI models like ChatGPT map out language patterns but don't actually understand language. AI models can quickly generate low-value written work and assist with coding tasks. However, challenges like bias and stolen training data pose ethical issues. While AI advancements are impressive, achieving artificial general intelligence (AGI) remains a distant concept. The future of AI innovation and its potential impact on society are uncertain.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487433, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=3217, total_tokens=3317))\n","ChatCompletion(id='chatcmpl-A3sOQb2DLn7lDOGqCAL24y3QWzdrX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Orby AI is developing AI agents that can autonomously perform tasks such as data entry and document processing, aiming to revolutionize business workflows. The founders, Bella Liu and William Lu, bring experience from IBM, UiPath, Nvidia, and Google Cloud to create a platform that learns and acts on workflows in real time. Orby's cloud-based generative AI model utilizes symbolic AI to adapt to changes in workflows intelligently. Despite competition in the sector, Orby raised $30 million in a Series A funding round and plans to expand its team and go-to-market strategy. The company prioritizes customer data privacy, using telemetry data for model improvement while keeping humans in the feedback loop.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487434, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=137, prompt_tokens=1154, total_tokens=1291))\n","ChatCompletion(id='chatcmpl-A3sOSRZfTbwsDHuGzesyfDAH3Wrop', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The UK is expanding efforts in AI safety by opening a second location in San Francisco to be closer to the epicenter of AI development. The AI Safety Institute, launched in November 2023, currently has 32 employees and recently released tools for testing the safety of foundational AI models. Despite the challenge of benchmarking models, the institute aims to engage with AI companies to evaluate them and make AI safe across society. The UK plans to develop more AI legislation in the future, but will only do so once the scope of AI risks is better understood. The institute's goal is to take an international approach to AI safety, collaborate with other countries, and incentivize more research globally.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487436, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=136, prompt_tokens=1180, total_tokens=1316))\n","ChatCompletion(id='chatcmpl-A3sOUwkmyeORnhyb7MUWOhdGWiNwv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Apple announced several AI features at WWDC 2024, including a revamped Siri that can now handle speech stumbles and better understand context. The new Siri can also type responses and take actions in and across apps. ChatGPT, a chatbot experience from OpenAI, will be integrated into Siri and other first-party apps on Apple devices. Genmoji, a feature coming to iOS 18, allows users to create AI emoji-like images of people in their photo library. The upgraded Photos app includes tools like Clean Up to remove unwanted elements and better organization of photos using AI. iOS 18 will introduce optional call transcription and summaries in the Notes app for iPhone 15 Pro and newer models.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487438, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=140, prompt_tokens=1217, total_tokens=1357))\n","ChatCompletion(id='chatcmpl-A3sOXFB0b7nj3UrVv4FBqbtFes2GV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='EasyTranslate has shifted towards an AI-driven platform called “HumanAI” to improve content translation efficiency by combining human expertise with large language models (LLMs). This platform utilizes LLMs to generate short-term memory for more accurate translations, only involving humans where needed. By leveraging LLMs and customer data, EasyTranslate can offer customized content translations at a fraction of the cost, pricing at €0.01 per word. The company aims to provide added value by combining AI with human feedback, standing out against pure AI-based solutions in the market. Backed by €3 million in funding, EasyTranslate seeks to compete in the global translation market by offering efficient and cost-effective services to businesses like Wix and Monday.com.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487441, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=145, prompt_tokens=1065, total_tokens=1210))\n","ChatCompletion(id='chatcmpl-A3sOZjQMelywaB7xOaumc3FAjtTPP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Apple has signed the White House's commitment to AI safety, joining 15 other tech companies in developing safe, secure, and trustworthy AI. The company will soon launch Apple Intelligence, a generative AI offering, to its 2 billion users. By embedding ChatGPT in the iPhone, Apple is going all in on generative AI. The commitment includes stress testing AI models before public release, treating model weights confidentially, and developing content labeling systems. The White House's stance on open-source AI models could impact the industry significantly, as federal agencies have made progress in AI-related tasks following President Biden's executive order.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487443, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=124, prompt_tokens=745, total_tokens=869))\n","ChatCompletion(id='chatcmpl-A3sObTK3i2oPgdsByxhFkChGQqA8X', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Ashish Nagar, a former Amazon Alexa engineer, founded Level AI to apply AI algorithms to contact center tasks and improve productivity. The platform automates customer service tasks and provides insights for managers and agents, such as scoring agents on metrics like total conversations and \"dead air.\" Level AI can show hints to agents during conversations, gauge customer sentiment, and offer coaching tools to improve performance. Despite concerns about data privacy and job displacement, Level AI offers flexibility for customers to control and manage their data. The company has attracted customers like Affirm and Penske, and recently closed a $39.4 million Series C funding round to expand its platform to new customer segments. With a growing market for contact center software expected to reach $145.20 billion by 2029, Level AI aims to continue innovating and expanding its workforce to meet demand.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487445, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=168, prompt_tokens=1053, total_tokens=1221))\n","ChatCompletion(id='chatcmpl-A3sOdZM6DAztFTxOzLoj76yLDmlS9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Ilya Sutskever, former chief scientist at OpenAI, has launched a new AI company, Safe Superintelligence Inc. (SSI), with former Y Combinator partner Daniel Gross and ex-OpenAI engineer Daniel Levy. Sutskever left OpenAI after a falling out with leadership over AI safety approaches, along with co-worker Jan Leike, who now heads a team at rival AI shop Anthropic. Sutskever has long emphasized the importance of AI safety, predicting that superintelligent AI may arrive within the decade and emphasizing the need for research into controlling and restricting it. SSI, unlike OpenAI, is for-profit and designed to advance capabilities rapidly while prioritizing safety, with a focus on revolutionary engineering and scientific breakthroughs. The company is currently recruiting technical talent in Palo Alto and Tel Aviv and is likely to attract significant funding due to interest in AI and the team's credentials.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487447, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=184, prompt_tokens=746, total_tokens=930))\n","ChatCompletion(id='chatcmpl-A3sOg9EVaButYwHrtkrzi5xhkCgkV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Harvey Mason Jr., CEO of the Recording Academy, announced that the Grammys would accept music made with AI in the creative process, leading to concerns about the music industry's future. AI is already being used in music for mastering and equalizing sounds, raising issues about copyrights, royalties, and fair compensation for artists. Mason launched the Human Artistry Campaign to address these concerns and advocate for more regulations around the use of AI in music. The industry is grappling with how to protect artists from unauthorized AI use, with recent incidents involving Drake and Tupac's estate sparking legal battles. While some embrace AI in music, others, like Devante, the Artist, believe it shouldn't exist and call for more safeguards to protect human creativity.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487450, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=147, prompt_tokens=1542, total_tokens=1689))\n","ChatCompletion(id='chatcmpl-A3sOjxXWihBMrrAtamM7RNW6bYdlQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Miriam Vogel, CEO of EqualAI, emphasizes the importance of responsible AI governance and reducing unconscious bias in AI. Vogel's background in law and policy brings a unique perspective to the AI industry. She advocates for more diversity and inclusion in AI development to ensure AI works for all consumers. AI literacy is essential for everyone to thrive in an AI-powered economy. Standardized measures and metrics are needed to evaluate AI systems and build trust. Users should be aware of bias and potential harms in AI, and building AI responsibly requires asking key questions and following best practices. Investors play a crucial role in pushing for responsible AI to ensure safety, effectiveness, and public trust.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487453, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=133, prompt_tokens=1864, total_tokens=1997))\n","ChatCompletion(id='chatcmpl-A3sOkUOsD5gneTplPIbytSoKXaROb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Nova AI, a startup focused on code-testing, is using open source models like Llama and StarCoder instead of OpenAI's GPT-4. The company aims to target mid-size to large enterprises with complex code bases. They use their own open source embedding models to avoid sending customer data to OpenAI and rely on open source AI models for writing tests. By avoiding OpenAI, Nova AI not only appeases enterprise concerns about data privacy but also finds open source models to be cheaper and more effective for specific tasks. The company's co-founders have backgrounds in big tech companies like Google and Meta, and are confident in the rapid progress of open source AI models.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487454, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=135, prompt_tokens=1196, total_tokens=1331))\n","ChatCompletion(id='chatcmpl-A3sOn8B16QDXwuZTkP4X4L7CKowqc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Exa is building a unique search engine that caters to AI models rather than humans, allowing them to search for information and return accurate answers. The startup recently raised $17 million in Series A funding led by Lightspeed, Nvidia, and Y Combinator, bringing their total funding to $22 million. The founders, Harvard alumni Will Bryk and Jeff Wang, initially focused on improving search using AI before pivoting to serve AI companies who needed an API version of their search engine. Their product has gained significant traction, serving thousands of developers and catering to various use cases including training data curation for companies like Databricks. While not aiming to upend Google, Exa's approach to AI-focused search engines could pose a threat to traditional search hegemony in the future.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487457, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=157, prompt_tokens=1073, total_tokens=1230))\n","ChatCompletion(id='chatcmpl-A3sOpaOvjeB9vPk802amiLuZMpBlc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Businesses are increasingly turning to \"emotion AI\" to help AI bots better understand human emotion, as predicted by PitchBook\\'s Enterprise SaaS Emerging Tech Research report. Emotion AI, a more advanced form of sentiment analysis, uses sensors, machine learning, and psychology to detect human emotion during interactions. Major AI cloud providers offer emotion AI capabilities, making it more accessible in the business world. Startups like Uniphore and MorphCast are emerging to meet the demand for emotion AI technology. However, there are concerns about the effectiveness of emotion AI, as research suggests that human emotion cannot be accurately determined by facial movements. Additionally, AI regulations like the European Union\\'s AI Act may limit the use of emotion detection systems. Silicon Valley is pushing for AI bots with emotional understanding, but the effectiveness of this technology remains uncertain.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487459, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=164, prompt_tokens=1047, total_tokens=1211))\n","ChatCompletion(id='chatcmpl-A3sOtas4lM8MjIu88sdyf3Qq7uWsn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"SUSE, a well-known open source company in Europe, is aiming to break into the U.S. market with its AI solutions and strategy. The company's CEO highlighted the importance of open source in driving innovation and evolution in the tech industry. SUSE has seen success in attracting former CentOS users after Red Hat's changes, showing the appeal of their offerings. The company's AI solution focuses on enabling businesses to put AI workloads into production securely and privately, catering to the need for data control and compliance. Modular and open-source, the SUSE AI solution has already attracted customers like Fujitsu.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487463, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=120, prompt_tokens=1576, total_tokens=1696))\n","ChatCompletion(id='chatcmpl-A3sOvWGBpeR97oAW9zttscdW0bYWG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='MIT researchers have developed an AI risk repository with over 700 AI risks grouped by causal factors, domains, and subdomains to help policymakers, stakeholders, and the AI industry. Existing risk frameworks cover only a fraction of the risks identified in the repository, highlighting the need for a more comprehensive approach to understanding AI risks. The repository aims to save time, increase oversight, and provide a foundation for more specific work in AI risk evaluation. The researchers plan to evaluate how different AI risks are being addressed in the next phase of their research using the repository. While alignment on AI risks is important, it may not be sufficient to spur competent regulation of AI systems.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1725487465, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=130, prompt_tokens=1121, total_tokens=1251))\n"]}],"source":["summaries = {}\n","for i in pairs.keys():\n","  content = f\"\"\"\n","  Sumarize the following information in a TL:DR format with at least 5 sentences for easier cosumption. Do not include the term TL:DR in the final output. Capture key points and figures used in this article:\n","  title: {i}\n","  aritcle: {pairs[i]}\n","  \"\"\"\n","\n","  completion = openai.chat.completions.create(\n","  messages=[\n","      {\n","          \"role\": \"user\",\n","          \"content\": content,\n","      }\n","  ],\n","  model=\"gpt-3.5-turbo\",\n","  )\n","\n","  summaries[i] = completion.choices[0].message.content.replace('\\\\n',' ').replace('TL;DR','').replace('TL;DR:',' ').replace('\\n',' ').replace('TL:DR','').replace('TL:DR:','')\n","  print(completion)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"re3KieaT_b-x"},"outputs":[],"source":["df2 = pd.DataFrame(list(summaries.items()), columns=['Title', 'Text'])\n","df2.to_csv('techcrunchsummaries.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1725487469387,"user":{"displayName":"Mitchel Crosson","userId":"11140833460202076022"},"user_tz":300},"id":"0bQAkv1w_it9","outputId":"8be54e79-f995-4d7c-8f12-786e9de9ea97"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"df2\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"\\u2018Emotion AI\\u2019 may be the next trend for business software, and that could be problematic\",\n          \"WTF is AI?\",\n          \"Grammy CEO says music industry also has AI concerns\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Businesses are increasingly turning to \\\"emotion AI\\\" to help AI bots better understand human emotion, as predicted by PitchBook's Enterprise SaaS Emerging Tech Research report. Emotion AI, a more advanced form of sentiment analysis, uses sensors, machine learning, and psychology to detect human emotion during interactions. Major AI cloud providers offer emotion AI capabilities, making it more accessible in the business world. Startups like Uniphore and MorphCast are emerging to meet the demand for emotion AI technology. However, there are concerns about the effectiveness of emotion AI, as research suggests that human emotion cannot be accurately determined by facial movements. Additionally, AI regulations like the European Union's AI Act may limit the use of emotion detection systems. Silicon Valley is pushing for AI bots with emotional understanding, but the effectiveness of this technology remains uncertain.\",\n          \"Artificial intelligence (AI) is software that approximates human thinking, using large statistical models to predict patterns. AI models like ChatGPT map out language patterns but don't actually understand language. AI models can quickly generate low-value written work and assist with coding tasks. However, challenges like bias and stolen training data pose ethical issues. While AI advancements are impressive, achieving artificial general intelligence (AGI) remains a distant concept. The future of AI innovation and its potential impact on society are uncertain.\",\n          \"Harvey Mason Jr., CEO of the Recording Academy, announced that the Grammys would accept music made with AI in the creative process, leading to concerns about the music industry's future. AI is already being used in music for mastering and equalizing sounds, raising issues about copyrights, royalties, and fair compensation for artists. Mason launched the Human Artistry Campaign to address these concerns and advocate for more regulations around the use of AI in music. The industry is grappling with how to protect artists from unauthorized AI use, with recent incidents involving Drake and Tupac's estate sparking legal battles. While some embrace AI in music, others, like Devante, the Artist, believe it shouldn't exist and call for more safeguards to protect human creativity.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"df2"},"text/html":["\n","  <div id=\"df-304c52b0-f03f-4971-b17e-85aa8185a106\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>OmniAI transforms business data for AI</td>\n","      <td>OmniAI, founded by Anna Pojawis and Tyler Mara...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Mayfield allocates $100M to AI incubator model...</td>\n","      <td>Mayfield Fund is launching AI Garage, a $100 m...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>At the AI Film Festival, humanity triumphed ov...</td>\n","      <td>At the AI Film Festival, AI was used in variou...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Microsoft dodges UK antitrust scrutiny over it...</td>\n","      <td>Microsoft's recent investment in Mistral AI av...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>EU calls for help with shaping rules for gener...</td>\n","      <td>EU is seeking input from stakeholders on rules...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-304c52b0-f03f-4971-b17e-85aa8185a106')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-304c52b0-f03f-4971-b17e-85aa8185a106 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-304c52b0-f03f-4971-b17e-85aa8185a106');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-03d22889-764e-49bf-ac00-31c4189adb0b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03d22889-764e-49bf-ac00-31c4189adb0b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-03d22889-764e-49bf-ac00-31c4189adb0b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                               Title  \\\n","0             OmniAI transforms business data for AI   \n","1  Mayfield allocates $100M to AI incubator model...   \n","2  At the AI Film Festival, humanity triumphed ov...   \n","3  Microsoft dodges UK antitrust scrutiny over it...   \n","4  EU calls for help with shaping rules for gener...   \n","\n","                                                Text  \n","0  OmniAI, founded by Anna Pojawis and Tyler Mara...  \n","1  Mayfield Fund is launching AI Garage, a $100 m...  \n","2  At the AI Film Festival, AI was used in variou...  \n","3  Microsoft's recent investment in Mistral AI av...  \n","4  EU is seeking input from stakeholders on rules...  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df2.head()"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
